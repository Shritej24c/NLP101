{"cells":[{"cell_type":"markdown","metadata":{"id":"hxg5WO71MFbh"},"source":["# <Font color = 'pickle'>**PyTorch Embedding Layers**"]},{"cell_type":"markdown","metadata":{"id":"WntQds6hJwQx"},"source":["In this lecture we will learn more about embeddings like how to use torch.nn.Embedding and torch.nn.EmbeddingBag."]},{"cell_type":"markdown","metadata":{"id":"mZKcjyG1UzNL"},"source":["# <Font color = 'pickle'>**Introduction**"]},{"cell_type":"markdown","metadata":{"id":"yp5rhAWsMPp0"},"source":["<font size = 5, color = 'pickle'>**Embedding**\n","\n","- This layer is a lookup table that stores word embeddings of a fixed dictionary and size.\n","- The word embeddings can be retrieved using indices, where the index is the index of the word in the vocabulary.\n","- The input to this layer is a sequence of integer indices, where each index represents a word in the input sentence or document.\n","- The output of this layer is a sequence of word embeddings, where each embedding represents a word in the input sequence.\n","- The embeddings are initialized randomly and are learned during training using backpropagation.\n","- The size of the embeddings is specified when the layer is created, and is typically a hyperparameter that is tuned based on the specific task and dataset.\n","- This layer is commonly used in natural language processing (NLP) tasks, such as text classification, sentiment analysis, and machine translation."]},{"cell_type":"markdown","metadata":{"id":"qcmz6kuCSTai"},"source":["<font size = 5, color = 'pickle'>**EmbeddingBag**\n","\n","* This is an extension of nn.Embedding layer.\n","* In simple terms, EmbeddingBag is a two step process:\n","    - The first step is to create an embedding and the second step is to reduce (sum/mean/max, according to the \"mode\" argument) the embedding output across dimension 1.\n","    - So we can get the same result that nn.EmbeddingBag gives by calling torch.nn.functional.embedding, followed by torch.sum/mean/max.\n","* However, EmbeddingBag is much more time and memory efficient than using a Embedding followed by sum/min/max."]},{"cell_type":"markdown","metadata":{"id":"gA39SxMpTSFj"},"source":["# <font color = 'pickle'> **Install/ Update/ Import useful libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:57:59.534933Z","start_time":"2021-04-14T13:57:59.525480Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8718,"status":"ok","timestamp":1694998142670,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"AbfVc6MlOtSw","outputId":"b4a5eb60-2062-43e7-e207-df86eff9ac10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n","Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (2.0.4)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","    !pip install torchtext --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:55:12.420649Z","start_time":"2021-04-14T14:55:12.214786Z"},"execution":{"iopub.execute_input":"2022-04-08T10:08:08.380659Z","iopub.status.busy":"2022-04-08T10:08:08.380443Z","iopub.status.idle":"2022-04-08T10:08:09.325309Z","shell.execute_reply":"2022-04-08T10:08:09.324819Z","shell.execute_reply.started":"2022-04-08T10:08:08.380588Z"},"id":"X0N0Bt07QdQm","tags":[]},"outputs":[],"source":["# Import PyTorch library for tensor computation and deep learning\n","import torch\n","\n","# Import neural network module from PyTorch for building neural network layers\n","import torch.nn as nn\n","\n","# Import pandas for data manipulation and analysis\n","import pandas as pd\n","\n","# Import vocab from torchtext for handling vocabulary and text preprocessing\n","from torchtext.vocab import vocab\n","\n","# Import Counter from collections for counting elements in collections like lists\n","from collections import Counter\n","\n","# Import Dataset and DataLoader from PyTorch for handling data loading and batching\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"markdown","metadata":{"id":"2OMA0kgAT-xy"},"source":["# <Font color = 'pickle'>**Load Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:49.684561Z","start_time":"2021-04-14T13:53:49.682122Z"},"execution":{"iopub.execute_input":"2022-04-08T10:08:09.623326Z","iopub.status.busy":"2022-04-08T10:08:09.623200Z","iopub.status.idle":"2022-04-08T10:08:09.625802Z","shell.execute_reply":"2022-04-08T10:08:09.625381Z","shell.execute_reply.started":"2022-04-08T10:08:09.623312Z"},"id":"J2szUi0yyjku","tags":[]},"outputs":[],"source":["# Generate some data\n","data = {\n","    \"label\": [0, 1, 1, 0],\n","    \"data\": [\n","        \"Movie was bad\",\n","        \"Movie was good\",\n","        \"It was thrilling.\",\n","        \"It was horrible. \"\n","    ]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:50.165322Z","start_time":"2021-04-14T13:53:50.159797Z"},"execution":{"iopub.execute_input":"2022-04-08T10:08:10.718047Z","iopub.status.busy":"2022-04-08T10:08:10.717890Z","iopub.status.idle":"2022-04-08T10:08:10.722383Z","shell.execute_reply":"2022-04-08T10:08:10.721942Z","shell.execute_reply.started":"2022-04-08T10:08:10.718034Z"},"id":"-8z6L8Njy0uf","tags":[]},"outputs":[],"source":["df = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:50.663231Z","start_time":"2021-04-14T13:53:50.655876Z"},"colab":{"base_uri":"https://localhost:8080/","height":175},"execution":{"iopub.execute_input":"2022-04-08T10:08:11.198870Z","iopub.status.busy":"2022-04-08T10:08:11.198665Z","iopub.status.idle":"2022-04-08T10:08:11.206672Z","shell.execute_reply":"2022-04-08T10:08:11.206333Z","shell.execute_reply.started":"2022-04-08T10:08:11.198858Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1694998308443,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"5qO4GDkey4hd","outputId":"71f4874d-6aac-4f7f-92cc-9f3c4470fcc5","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   label               data\n","0      0      Movie was bad\n","1      1     Movie was good\n","2      1  It was thrilling.\n","3      0  It was horrible. "],"text/html":["\n","  <div id=\"df-f16829d8-ddce-4b0c-9487-0ca6cba7799d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Movie was bad</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Movie was good</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>It was thrilling.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>It was horrible.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f16829d8-ddce-4b0c-9487-0ca6cba7799d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f16829d8-ddce-4b0c-9487-0ca6cba7799d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f16829d8-ddce-4b0c-9487-0ca6cba7799d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-954b614d-e696-4ce2-ad65-e0670cdbddff\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-954b614d-e696-4ce2-ad65-e0670cdbddff')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-954b614d-e696-4ce2-ad65-e0670cdbddff button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":9}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"48WpX7IjUCPm"},"source":["# <Font color = 'pickle'>**Create Custom Torch Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:51.227570Z","start_time":"2021-04-14T13:53:51.222144Z"},"execution":{"iopub.execute_input":"2022-04-08T10:08:13.238596Z","iopub.status.busy":"2022-04-08T10:08:13.238445Z","iopub.status.idle":"2022-04-08T10:08:13.242287Z","shell.execute_reply":"2022-04-08T10:08:13.241859Z","shell.execute_reply.started":"2022-04-08T10:08:13.238583Z"},"id":"hlgbM1PVWgkm","tags":[]},"outputs":[],"source":["X = df['data']\n","y = df['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:51.741188Z","start_time":"2021-04-14T13:53:51.734324Z"},"execution":{"iopub.execute_input":"2022-04-08T10:08:14.063125Z","iopub.status.busy":"2022-04-08T10:08:14.062988Z","iopub.status.idle":"2022-04-08T10:08:14.066652Z","shell.execute_reply":"2022-04-08T10:08:14.066298Z","shell.execute_reply.started":"2022-04-08T10:08:14.063112Z"},"id":"QFMuv5sZQke5","tags":[]},"outputs":[],"source":["class CustomDataset(Dataset):\n","    \"\"\"\n","    Custom Dataset class inheriting from PyTorch's Dataset class.\n","    Intended to handle custom text and label data.\n","\n","    Attributes:\n","        X (pd.Series): The input features (text).\n","        y (pd.Series): The labels corresponding to the input features.\n","    \"\"\"\n","\n","    def __init__(self, X, y):\n","        \"\"\"\n","        Initialize the dataset with input features and labels.\n","\n","        Parameters:\n","            X (pd.Series): Input features.\n","            y (pd.Series): Labels corresponding to input features.\n","        \"\"\"\n","        self.X = X  # Input features (text)\n","        self.y = y  # Corresponding labels\n","\n","    def __len__(self):\n","        \"\"\"\n","        Return the total number of samples in the dataset.\n","\n","        Returns:\n","            int: Number of samples in the dataset.\n","        \"\"\"\n","        return len(self.X)  # Return the length of the dataset\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Fetch and return a single sample from the dataset at the given index.\n","\n","        Parameters:\n","            idx (int): Index of the sample to fetch.\n","\n","        Returns:\n","            tuple: A tuple containing the label and the input feature (text) at the index.\n","        \"\"\"\n","        text = self.X.iloc[idx]  # Fetch the input feature at the given index\n","        labels = self.y.iloc[idx]  # Fetch the corresponding label\n","        sample = (labels, text)  # Create a tuple of label and input feature\n","\n","        return sample  # Return the sample as a tuple\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:52.252309Z","start_time":"2021-04-14T13:53:52.247055Z"},"execution":{"iopub.execute_input":"2022-04-08T10:08:16.572946Z","iopub.status.busy":"2022-04-08T10:08:16.572805Z","iopub.status.idle":"2022-04-08T10:08:16.575384Z","shell.execute_reply":"2022-04-08T10:08:16.575034Z","shell.execute_reply.started":"2022-04-08T10:08:16.572933Z"},"id":"6hS3eltrzeke","tags":[]},"outputs":[],"source":["# Create an instance of CustomDataset with the input features X and labels y for training\n","train_dataset = CustomDataset(X, y)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-04-08T10:13:22.093799Z","iopub.status.busy":"2022-04-08T10:13:22.093657Z","iopub.status.idle":"2022-04-08T10:13:22.096913Z","shell.execute_reply":"2022-04-08T10:13:22.096639Z","shell.execute_reply.started":"2022-04-08T10:13:22.093786Z"},"executionInfo":{"elapsed":545,"status":"ok","timestamp":1694998443409,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"L6Gaq6NlYhTI","outputId":"bb88d5de-f200-4994-c32b-0c453506578f","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["0 0 Movie was bad\n","1 1 Movie was good\n","2 1 It was thrilling.\n","3 0 It was horrible. \n"]}],"source":["# Iterate through the train_dataset, printing the index, label (y), and input feature (x) for each sample\n","for i, (y, x) in enumerate(train_dataset):\n","    print(i, y, x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:52.744982Z","start_time":"2021-04-14T13:53:52.734486Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-04-08T10:16:06.208551Z","iopub.status.busy":"2022-04-08T10:16:06.208317Z","iopub.status.idle":"2022-04-08T10:16:06.213098Z","shell.execute_reply":"2022-04-08T10:16:06.212762Z","shell.execute_reply.started":"2022-04-08T10:16:06.208533Z"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1694998558181,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"gftq2R1cOtTH","outputId":"e1d41739-270f-471c-c7a3-0e4413ab497c","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 'It was thrilling.')"]},"metadata":{},"execution_count":19}],"source":["# Retrieve the sample at index 2 from train_dataset using the __getitem__ method\n","train_dataset.__getitem__(2)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1694998601037,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"vg2SNFVsGSiM","outputId":"463a4efa-8931-42d2-d8e3-c59939855c43"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 'It was thrilling.')"]},"metadata":{},"execution_count":20}],"source":["# Retrieve the sample at index 2 from train_dataset using Python's built-in indexing syntax\n","train_dataset[2]\n"]},{"cell_type":"markdown","source":["Key Points:\n","\n","1. **Retrieval**: The line is used to fetch the sample located at index 2 in `train_dataset`.\n","2. **Syntactic Sugar**: It utilizes Python's built-in indexing syntax, which internally calls the `__getitem__` method.\n","\n"],"metadata":{"id":"Nbt9bys_yhsR"}},{"cell_type":"markdown","metadata":{"id":"WsstIAY3UsUk"},"source":["# <Font color = 'pickle'>**Create Vocab**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:53.277598Z","start_time":"2021-04-14T13:53:53.271982Z"},"execution":{"iopub.execute_input":"2022-02-17T02:20:08.237074Z","iopub.status.busy":"2022-02-17T02:20:08.236959Z","iopub.status.idle":"2022-02-17T02:20:08.239882Z","shell.execute_reply":"2022-02-17T02:20:08.239564Z","shell.execute_reply.started":"2022-02-17T02:20:08.237061Z"},"id":"FDkn4P9a4H0P"},"outputs":[],"source":["# Initialize an empty Counter object to hold the word frequencies\n","counter = Counter()\n","\n","# Loop through each sample in train_dataset to count word occurrences\n","for (label, line) in train_dataset:\n","    # Split the line into words and update their frequencies in the counter\n","    counter.update(str(line).split())\n"]},{"cell_type":"markdown","source":["Key Points:\n","\n","1. **Counter Initialization**: A Counter object is initialized to hold the frequencies of individual words.\n","2. **Dataset Looping**: The `for` loop iterates through each sample in `train_dataset`.\n","3. **Word Counting**: Each line (text sample) is split into words, which are then used to update the Counter object.\n"],"metadata":{"id":"GnjSU0j6y1JS"}},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:54.287115Z","start_time":"2021-04-14T13:53:54.283099Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:08.811157Z","iopub.status.busy":"2022-02-17T02:20:08.811002Z","iopub.status.idle":"2022-02-17T02:20:08.814172Z","shell.execute_reply":"2022-02-17T02:20:08.813849Z","shell.execute_reply.started":"2022-02-17T02:20:08.811143Z"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1694998707817,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"l728QWX3zkxM","outputId":"605a25fe-6d21-46e8-9d0b-628672cf5059"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'Movie': 2,\n","         'was': 4,\n","         'bad': 1,\n","         'good': 1,\n","         'It': 2,\n","         'thrilling.': 1,\n","         'horrible.': 1})"]},"metadata":{},"execution_count":22}],"source":["counter"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:53:57.197701Z","start_time":"2021-04-14T13:53:57.195242Z"},"execution":{"iopub.execute_input":"2022-02-17T02:20:09.961948Z","iopub.status.busy":"2022-02-17T02:20:09.961833Z","iopub.status.idle":"2022-02-17T02:20:09.992676Z","shell.execute_reply":"2022-02-17T02:20:09.992382Z","shell.execute_reply.started":"2022-02-17T02:20:09.961935Z"},"id":"TyO1xB9dzrdY"},"outputs":[],"source":["# Create a vocabulary using the word frequencies stored in the counter, with a minimum frequency of 1 for inclusion\n","my_vocab = vocab(counter, min_freq=1)\n"]},{"cell_type":"markdown","source":["Key Points:\n","\n","1. **Vocabulary Creation**: The line initializes a vocabulary object using the word frequencies gathered so far.\n","2. **Minimum Frequency**: Words are included in the vocabulary only if their frequency is at least 1, as specified by the `min_freq` parameter."],"metadata":{"id":"D6L3MhdTzFtg"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:10.667855Z","iopub.status.busy":"2022-02-17T02:20:10.667732Z","iopub.status.idle":"2022-02-17T02:20:10.670823Z","shell.execute_reply":"2022-02-17T02:20:10.670542Z","shell.execute_reply.started":"2022-02-17T02:20:10.667841Z"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1694998815041,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"U9H1bo8STstA","outputId":"f81f417c-2049-45c4-c9a1-996db7f3c4c8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Vocab()"]},"metadata":{},"execution_count":25}],"source":["# Output or examine the contents of the my_vocab object to understand the constructed vocabulary\n","my_vocab\n"]},{"cell_type":"markdown","source":["Key Points:\n","\n","1. **Output/Examination**: The line is likely used to output or inspect the `my_vocab` object.\n","2. **Vocabulary Object**: `my_vocab` holds the vocabulary constructed from the word frequencies in the dataset.\n","\n"],"metadata":{"id":"ZccD9cUczV7N"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:11.192690Z","iopub.status.busy":"2022-02-17T02:20:11.192564Z","iopub.status.idle":"2022-02-17T02:20:11.195610Z","shell.execute_reply":"2022-02-17T02:20:11.195351Z","shell.execute_reply.started":"2022-02-17T02:20:11.192676Z"},"executionInfo":{"elapsed":184,"status":"ok","timestamp":1694998891769,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"A3i8rGocHHBc","outputId":"62ded282-7770-45b7-955d-20f61a6f4a6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'thrilling.': 5,\n"," 'bad': 2,\n"," 'was': 1,\n"," 'horrible.': 6,\n"," 'It': 4,\n"," 'good': 3,\n"," 'Movie': 0}"]},"metadata":{},"execution_count":26}],"source":["# Retrieve the word-to-index mapping from the my_vocab object\n","my_vocab.get_stoi()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T02:20:12.002126Z","iopub.status.busy":"2022-02-17T02:20:12.002008Z","iopub.status.idle":"2022-02-17T02:20:12.004672Z","shell.execute_reply":"2022-02-17T02:20:12.004305Z","shell.execute_reply.started":"2022-02-17T02:20:12.002113Z"},"id":"pmXMfOTrdlVs"},"outputs":[],"source":["# Insert the '<unk>' token at index 0 in my_vocab to represent any unknown words\n","my_vocab.insert_token('<unk>', 0)\n"]},{"cell_type":"markdown","source":["Key Points:\n","\n","1. **Token Insertion**: The line adds a special token `<unk>` to the vocabulary.\n","2. **Handling Unknown Words**: The purpose of this token is to represent any unknown words encountered during the model's operation.\n","3. **Index Position**: The token is inserted at index 0, as specified by the second argument."],"metadata":{"id":"VovEVtUK0JJ0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:12.783002Z","iopub.status.busy":"2022-02-17T02:20:12.782880Z","iopub.status.idle":"2022-02-17T02:20:12.785996Z","shell.execute_reply":"2022-02-17T02:20:12.785750Z","shell.execute_reply.started":"2022-02-17T02:20:12.782989Z"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1694999046218,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"YqFbBSLTdnrc","outputId":"56638a3a-077b-4cb4-cf98-db0177706bf9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'thrilling.': 6,\n"," 'bad': 3,\n"," 'was': 2,\n"," 'horrible.': 7,\n"," 'It': 5,\n"," 'good': 4,\n"," 'Movie': 1,\n"," '<unk>': 0}"]},"metadata":{},"execution_count":28}],"source":["# check mapping of words to index\n","my_vocab.get_stoi()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:54:02.249539Z","start_time":"2021-04-14T13:54:02.245640Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:14.898064Z","iopub.status.busy":"2022-02-17T02:20:14.897944Z","iopub.status.idle":"2022-02-17T02:20:14.901063Z","shell.execute_reply":"2022-02-17T02:20:14.900771Z","shell.execute_reply.started":"2022-02-17T02:20:14.898051Z"},"executionInfo":{"elapsed":187,"status":"ok","timestamp":1694999058223,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"xmdkw_zFWp9E","outputId":"7d13a2dd-310d-4b35-ec17-1d4720925828"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3]"]},"metadata":{},"execution_count":29}],"source":["# Print vocab indices for some random text\n","[my_vocab[token] for token in 'Movie was bad'.split()]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:16.292865Z","iopub.status.busy":"2022-02-17T02:20:16.292746Z","iopub.status.idle":"2022-02-17T02:20:16.295494Z","shell.execute_reply":"2022-02-17T02:20:16.295237Z","shell.execute_reply.started":"2022-02-17T02:20:16.292852Z"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1694999070539,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Q1BD86AyNIwm","outputId":"a4a69308-9a62-45f2-9a11-152b183016f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":30}],"source":["# check whether word hello is in dictionary\n","'hello' in my_vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:16.763846Z","iopub.status.busy":"2022-02-17T02:20:16.763703Z","iopub.status.idle":"2022-02-17T02:20:16.840742Z","shell.execute_reply":"2022-02-17T02:20:16.840250Z","shell.execute_reply.started":"2022-02-17T02:20:16.763831Z"},"executionInfo":{"elapsed":192,"status":"ok","timestamp":1694999076481,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Kl5sFsFHNPh2","outputId":"1ab7eca2-b3ba-4cbd-b318-cfbebc3c6a18","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["token not found in vocab\n"]}],"source":["# get the index for  the word hello\n","# since this word is not in the dictionary we should get an error\n","try:\n","    my_vocab['hello']\n","except RuntimeError:\n","    print('token not found in vocab')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T02:20:17.704877Z","iopub.status.busy":"2022-02-17T02:20:17.704754Z","iopub.status.idle":"2022-02-17T02:20:17.707075Z","shell.execute_reply":"2022-02-17T02:20:17.706730Z","shell.execute_reply.started":"2022-02-17T02:20:17.704864Z"},"id":"qPLkxrMwIJ7t"},"outputs":[],"source":["# set the default index to zero\n","# thus any uknown word will be represented b index 0 or token '<unk>'\n","my_vocab.set_default_index(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:18.107916Z","iopub.status.busy":"2022-02-17T02:20:18.107779Z","iopub.status.idle":"2022-02-17T02:20:18.110988Z","shell.execute_reply":"2022-02-17T02:20:18.110484Z","shell.execute_reply.started":"2022-02-17T02:20:18.107903Z"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1694999084750,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"E3YSbp6PRaSw","outputId":"5a32d1ba-863e-4142-aa01-e1874edff14a"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}],"source":["# again check if the word hello is in the dict\n","print('hello' in my_vocab)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:18.812870Z","iopub.status.busy":"2022-02-17T02:20:18.812661Z","iopub.status.idle":"2022-02-17T02:20:18.815957Z","shell.execute_reply":"2022-02-17T02:20:18.815591Z","shell.execute_reply.started":"2022-02-17T02:20:18.812855Z"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1694999087116,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"GPVvdTrWNe5-","outputId":"de8813c7-cd5a-4cf1-fcc8-7b5b9577c92d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":34}],"source":["# get the index for  the word hello\n","# since we set default index to 0, now it should return 0 for the word hello\n","my_vocab['hello']"]},{"cell_type":"markdown","metadata":{"id":"c8dk1o92ZGHS"},"source":["# <Font color = 'pickle'>**Create DataLoader for Embedding**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T13:54:02.791190Z","start_time":"2021-04-14T13:54:02.784792Z"},"execution":{"iopub.execute_input":"2022-02-17T02:20:20.432514Z","iopub.status.busy":"2022-02-17T02:20:20.432378Z","iopub.status.idle":"2022-02-17T02:20:20.435061Z","shell.execute_reply":"2022-02-17T02:20:20.434718Z","shell.execute_reply.started":"2022-02-17T02:20:20.432501Z"},"id":"czCW945vZh8y"},"outputs":[],"source":["def text_pipeline(x, vocab):\n","    \"\"\"\n","    Converts a text string into a list of vocabulary indices.\n","\n","    Parameters:\n","        x (str): The input text string to be converted.\n","        vocab (vocab object): The vocabulary object containing the word-to-index mapping.\n","\n","    Returns:\n","        list: A list of integers representing the vocabulary indices of the words in the input string.\n","    \"\"\"\n","    # Tokenize the input string, then map each token to its corresponding index in the given vocabulary\n","    return [vocab[token] for token in str(x).split()]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1694999181438,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"40W-LytDk2BC","outputId":"a934ff2f-8c0d-42fd-956d-894ab856b81b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3]"]},"metadata":{},"execution_count":38}],"source":["# check the function\n","text_pipeline('Movie was bad', my_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:23:31.460099Z","start_time":"2021-04-14T14:23:31.454202Z"},"execution":{"iopub.execute_input":"2022-02-17T02:20:21.437509Z","iopub.status.busy":"2022-02-17T02:20:21.437374Z","iopub.status.idle":"2022-02-17T02:20:21.441022Z","shell.execute_reply":"2022-02-17T02:20:21.440598Z","shell.execute_reply.started":"2022-02-17T02:20:21.437497Z"},"id":"56Bz-9U4ZvuE"},"outputs":[],"source":["def collate_batch(batch):\n","    \"\"\"\n","    Collates a batch of samples into tensors of labels and texts.\n","\n","    Parameters:\n","        batch (list): A list of tuples, each containing a label and a text.\n","\n","    Returns:\n","        tuple: A tuple containing two tensors, one for labels and one for texts.\n","    \"\"\"\n","    # Unpack the batch into separate lists for labels and texts\n","    labels, texts = zip(*batch)\n","\n","    # Convert the list of labels into a tensor of dtype int32\n","    labels = torch.tensor(labels, dtype=torch.int32)\n","\n","    # Convert the list of texts into a tensor; each text is transformed into a list of vocabulary indices using text_pipeline\n","    texts = torch.tensor([text_pipeline(text, my_vocab) for text in texts], dtype=torch.int32)\n","\n","    return labels, texts\n"]},{"cell_type":"markdown","metadata":{"id":"rfyFclISU_9n"},"source":["Code Explanation:\n","\n","- The function `collate_batch` accepts a list of tuples, each containing a `label` and a `text`.\n","- The statement `zip(*batch)` separates the list of tuples into two distinct lists: one for `labels` and another for `texts`.\n","- The list of `labels` is converted to a PyTorch tensor using `torch.tensor`. The data type (`dtype`) is explicitly set to `torch.int64` to ensure compatibility with PyTorch's requirements.\n","- The `texts` undergo a transformation via the `text_pipeline` function within a list comprehension. This results in a list of lists, where each inner list is a sequence of integer indices representing words. This list is then converted into a PyTorch tensor, also with the dtype set to `torch.int64` (not `torch.int32` as previously mentioned).\n","- Finally, the function returns a tuple consisting of the `labels` and `texts` tensors, ready for further processing.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JweJNFIqVwY1"},"source":["**----Digression Understanding zip, zip(*)-----**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1695007492487,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Jsyl3Du4VEEQ","outputId":"33cb6b5a-7de6-4bc1-b0a1-cf8711d54b8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 2, 3] [11, 12, 13] <zip object at 0x7dc7b3d12680>\n"]}],"source":["x = [1, 2, 3]\n","y = [11, 12, 13]\n","z = zip(x, y)\n","print(x, y, z)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xtbJGFCwVsM0"},"outputs":[],"source":["temp = list(z)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1695007509300,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"u2qV-xQtWdxL","outputId":"fadc4cfa-7823-4c5c-bcac-aa2bae937d9d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(1, 11), (2, 12), (3, 13)]"]},"metadata":{},"execution_count":43}],"source":["temp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":184,"status":"ok","timestamp":1695007513770,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"jNKe-jcpW4Rw","outputId":"6a46ac1e-94cf-4614-9c13-83e1b38e1c59"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 11)"]},"metadata":{},"execution_count":44}],"source":["temp[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bj87Y_fqVvaR"},"outputs":[],"source":["x1, y1 = zip(*temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1695007520712,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"9ITy8dLIWLJt","outputId":"0769afba-6097-48be-fc7a-bfeefa984f13"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 2, 3) (11, 12, 13)\n"]}],"source":["print(x1, y1)"]},{"cell_type":"markdown","metadata":{"id":"Ox7RZACtW8-t"},"source":["**----END of Digression-----**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:23:32.117967Z","start_time":"2021-04-14T14:23:32.113539Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:25.173262Z","iopub.status.busy":"2022-02-17T02:20:25.173122Z","iopub.status.idle":"2022-02-17T02:20:25.209845Z","shell.execute_reply":"2022-02-17T02:20:25.209390Z","shell.execute_reply.started":"2022-02-17T02:20:25.173249Z"},"executionInfo":{"elapsed":206,"status":"ok","timestamp":1695007542130,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ym__wP2NZy9f","outputId":"aa4f35a5-f274-4204-9dcd-724198271ddf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0, 1, 1, 0], dtype=torch.int32),\n"," tensor([[1, 2, 3],\n","         [1, 2, 4],\n","         [5, 2, 6],\n","         [5, 2, 7]], dtype=torch.int32))"]},"metadata":{},"execution_count":47}],"source":["# check the function by passing complete dataset\n","collate_batch(train_dataset)"]},{"cell_type":"markdown","metadata":{"id":"fXWnHudGY7dj"},"source":["As we can see we got the labels along with indices of words."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:23:44.739881Z","start_time":"2021-04-14T14:23:44.737097Z"},"execution":{"iopub.execute_input":"2022-02-17T02:20:26.102539Z","iopub.status.busy":"2022-02-17T02:20:26.102399Z","iopub.status.idle":"2022-02-17T02:20:26.105551Z","shell.execute_reply":"2022-02-17T02:20:26.105163Z","shell.execute_reply.started":"2022-02-17T02:20:26.102525Z"},"id":"ZIvdAEh6bfCO"},"outputs":[],"source":["# create DataLoader now\n","torch.manual_seed(0)\n","batch_size = 2\n","train_loader = DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           collate_fn=collate_batch,\n","                                           )"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:23:47.331320Z","start_time":"2021-04-14T14:23:47.225277Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:26.687866Z","iopub.status.busy":"2022-02-17T02:20:26.687724Z","iopub.status.idle":"2022-02-17T02:20:26.746677Z","shell.execute_reply":"2022-02-17T02:20:26.746315Z","shell.execute_reply.started":"2022-02-17T02:20:26.687852Z"},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1695007609180,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"TYLHhvI4iNI1","outputId":"ccb88bb4-b712-447c-9fac-4283e30484ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1], dtype=torch.int32) tensor([[5, 2, 6],\n","        [1, 2, 4]], dtype=torch.int32)\n","tensor([0, 0], dtype=torch.int32) tensor([[5, 2, 7],\n","        [1, 2, 3]], dtype=torch.int32)\n"]}],"source":["# iterate over the dataloader\n","torch.manual_seed(0)\n","for label, text in train_loader:\n","    print(label, text)"]},{"cell_type":"markdown","metadata":{"id":"WAgTA4hO8LCJ"},"source":["# <Font color = 'pickle'>**Embedding Layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:31:05.500487Z","start_time":"2021-04-14T14:31:05.498690Z"},"execution":{"iopub.execute_input":"2022-02-17T02:20:41.183295Z","iopub.status.busy":"2022-02-17T02:20:41.183156Z","iopub.status.idle":"2022-02-17T02:20:41.186291Z","shell.execute_reply":"2022-02-17T02:20:41.185848Z","shell.execute_reply.started":"2022-02-17T02:20:41.183282Z"},"id":"YrfCNo2Qi40i","tags":[]},"outputs":[],"source":["# Instantiating embedding layer with total number of embeddings and dimension of embedding i.e. dimesion of vector\n","torch.manual_seed(0)\n","model = nn.Embedding(num_embeddings=len(my_vocab), embedding_dim=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:41.676800Z","iopub.status.busy":"2022-02-17T02:20:41.676646Z","iopub.status.idle":"2022-02-17T02:20:41.681064Z","shell.execute_reply":"2022-02-17T02:20:41.680675Z","shell.execute_reply.started":"2022-02-17T02:20:41.676787Z"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1695007665547,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"ZGRTrN-OgQq7","outputId":"c4870012-9c9b-4af7-9ffb-5d72abadfd68","tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487],\n","        [ 0.6920, -0.3160, -2.1152,  0.3223, -1.2633],\n","        [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168],\n","        [-0.2473, -1.3527, -1.6959,  0.5667,  0.7935],\n","        [ 0.5988, -1.5551, -0.3414,  1.8530, -0.2159],\n","        [-0.7425,  0.5627,  0.2596, -0.1740, -0.6787],\n","        [ 0.9383,  0.4889,  1.2032,  0.0845, -1.2001],\n","        [-0.0048, -0.5181, -0.3067, -1.5810,  1.7066]], requires_grad=True)"]},"metadata":{},"execution_count":59}],"source":["# check the weights associated with the embedding layer\n","model.weight"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:33:05.440774Z","start_time":"2021-04-14T14:33:05.369800Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-02-17T02:20:58.477709Z","iopub.status.busy":"2022-02-17T02:20:58.477555Z","iopub.status.idle":"2022-02-17T02:20:58.516431Z","shell.execute_reply":"2022-02-17T02:20:58.516050Z","shell.execute_reply.started":"2022-02-17T02:20:58.477694Z"},"executionInfo":{"elapsed":177,"status":"ok","timestamp":1695007676564,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"WUiAbD3ajAjI","outputId":"d310dca6-410f-4454-e9a1-3d6ab5d98ab0","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","x\n"," tensor([[1, 2, 4],\n","        [5, 2, 6]], dtype=torch.int32)\n","\n","y\n"," tensor([1, 1], dtype=torch.int32)\n","\n","Output Shape \n"," torch.Size([2, 3, 5])\n","\n","Output\n"," tensor([[[ 0.6920, -0.3160, -2.1152,  0.3223, -1.2633],\n","         [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168],\n","         [ 0.5988, -1.5551, -0.3414,  1.8530, -0.2159]],\n","\n","        [[-0.7425,  0.5627,  0.2596, -0.1740, -0.6787],\n","         [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168],\n","         [ 0.9383,  0.4889,  1.2032,  0.0845, -1.2001]]],\n","       grad_fn=<EmbeddingBackward0>)\n","---------------------------------------------------------------------------\n","sentence_embedding\n","tensor([[ 0.5469, -0.5210, -0.7789,  1.1376, -0.1208],\n","        [ 0.1819,  0.4532,  0.5276,  0.3827, -0.2540]],\n","       grad_fn=<MeanBackward1>)\n","===========================================================================\n","\n","x\n"," tensor([[5, 2, 7],\n","        [1, 2, 3]], dtype=torch.int32)\n","\n","y\n"," tensor([0, 0], dtype=torch.int32)\n","\n","Output Shape \n"," torch.Size([2, 3, 5])\n","\n","Output\n"," tensor([[[-0.7425,  0.5627,  0.2596, -0.1740, -0.6787],\n","         [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168],\n","         [-0.0048, -0.5181, -0.3067, -1.5810,  1.7066]],\n","\n","        [[ 0.6920, -0.3160, -2.1152,  0.3223, -1.2633],\n","         [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168],\n","         [-0.2473, -1.3527, -1.6959,  0.5667,  0.7935]]],\n","       grad_fn=<EmbeddingBackward0>)\n","---------------------------------------------------------------------------\n","sentence_embedding\n","tensor([[-0.1325,  0.1176,  0.0243, -0.1724,  0.7149],\n","        [ 0.2649, -0.4535, -1.2304,  0.7089,  0.2157]],\n","       grad_fn=<MeanBackward1>)\n","===========================================================================\n"]}],"source":["# itertae over the dataloader and check the output of te model\n","for y, x in train_loader:\n","    output = model(x)\n","    print('\\nx\\n', x)\n","    print('\\ny\\n', y)\n","    print('\\nOutput Shape \\n', output.shape)\n","    print('\\nOutput\\n', output)\n","    sentence_embedding = torch.mean(output, dim=1)\n","    print('-'*75)\n","    print('sentence_embedding')\n","    print(sentence_embedding)\n","    print('='*75)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1695007736445,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"mB2PSQs5f0EV","outputId":"7fb06eda-59d6-493c-f986-b3890ba2a794"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.7425,  0.5627,  0.2596, -0.1740, -0.6787],\n","        [-0.2473, -1.3527, -1.6959,  0.5667,  0.7935],\n","        [ 0.5988, -1.5551, -0.3414,  1.8530, -0.2159],\n","        [-0.7425,  0.5627,  0.2596, -0.1740, -0.6787]],\n","       grad_fn=<EmbeddingBackward0>)"]},"metadata":{},"execution_count":61}],"source":["# check the model output for a random indices (sentence)\n","output = model(torch.tensor([5, 3, 4, 5]))\n","output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1695007738287,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"D2XeK08waPHd","outputId":"e5351f02-9d8c-422d-b904-4ab63701a143"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 5])"]},"metadata":{},"execution_count":62}],"source":["output.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181,"status":"ok","timestamp":1695007739674,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"-hRRV5fvgeNC","outputId":"b0d9b0ce-ea30-490b-b6bc-2dfdc5a301d8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.2834, -0.4456, -0.3795,  0.5179, -0.1950], grad_fn=<MeanBackward1>)"]},"metadata":{},"execution_count":63}],"source":["torch.mean(output, dim=0)"]},{"cell_type":"markdown","metadata":{"id":"A1Kk4o2dxrOp"},"source":["# <Font color = 'pickle'>**Create DataLoader for EmbeddingBag**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:37:00.304939Z","start_time":"2021-04-14T14:37:00.302202Z"},"id":"AEtkVKc3YnDx"},"outputs":[],"source":["def collate_batch(batch):\n","    \"\"\"\n","    Collates a batch of samples into tensors of labels, texts, and offsets.\n","\n","    Parameters:\n","        batch (list): A list of tuples, each containing a label and a text.\n","\n","    Returns:\n","        tuple: A tuple containing three tensors:\n","               - Labels tensor\n","               - Concatenated texts tensor\n","               - Offsets tensor indicating the start positions of each text in the concatenated tensor\n","    \"\"\"\n","    # Unpack the batch into separate lists for labels and texts\n","    labels, texts = zip(*batch)\n","\n","    # Convert the list of labels into a tensor of dtype int32\n","    labels = torch.tensor(labels, dtype=torch.int32)\n","\n","    # Convert the list of texts into a list of lists; each inner list contains the vocabulary indices for a text\n","    list_of_list_of_indices = [text_pipeline(text, my_vocab) for text in texts]\n","\n","    # Compute the offsets for each text in the concatenated tensor\n","    offsets = [0] + [len(i) for i in list_of_list_of_indices]\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","\n","    # Concatenate all text indices into a single tensor\n","    texts = torch.cat([torch.tensor(i, dtype=torch.int64) for i in list_of_list_of_indices])\n","\n","    return labels, texts, offsets\n","\n","\n","    # [[1,2,3 ], [3,4,5]]\n","    # [1,2,3,4,5,6] [0, 3]\n"]},{"cell_type":"markdown","metadata":{"id":"Nk9t42G8ra1N"},"source":["Code Explanation:\n","\n","- `text_pipeline` is a utility function that transforms a text string into a list of vocabulary indices. It takes a text string and a vocabulary object, then uses the vocabulary to map each word in the text to its corresponding index.\n","  \n","- `collate_batch` is designed to transform a batch of labeled text data into a format that can be directly fed into a neural network for training or inference.\n","  \n","- The function accepts an input batch, which is a list of tuples. Each tuple consists of a label (`label`) and a text string (`text`).\n","\n","- Inside `collate_batch`, `zip(*batch)` is utilized to separate the batch into two distinct lists: one for `labels` and another for `texts`.\n","\n","- The list of `labels` is promptly converted into a PyTorch tensor with data type set to `torch.int32`.\n","\n","- For each text string in `texts`, `text_pipeline` is invoked to transform it into a list of vocabulary indices. These lists are then stored in another list named `list_of_list_of_indices`.\n","\n","- The individual lists within `list_of_list_of_indices` are concatenated into a single PyTorch tensor using `torch.cat`. This tensor holds the entire batch of text data in index form.\n","\n","- To manage the original boundary of each text within the concatenated tensor, an `offsets` tensor is computed. It starts with a zero and is followed by the cumulative sum of the lengths of the individual text index lists.\n","\n","- The tensors for `labels`, `texts`, and `offsets` are packaged into a tuple and returned as the final output of `collate_batch`.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:37:04.704151Z","start_time":"2021-04-14T14:37:04.701804Z"},"id":"0gBYKbLvOtTb"},"outputs":[],"source":["# create data loader now\n","torch.manual_seed(0)\n","batch_size = 2\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           collate_fn=collate_batch,\n","                                           )"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:37:18.595940Z","start_time":"2021-04-14T14:37:18.502938Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1695008078713,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"iQ7viCd4Xhm4","outputId":"387df891-765d-4d67-d7c5-21763ca61448"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1], dtype=torch.int32) tensor([5, 2, 6, 1, 2, 4]) tensor([0, 3])\n","tensor([0, 0], dtype=torch.int32) tensor([5, 2, 7, 1, 2, 3]) tensor([0, 3])\n"]}],"source":["# iterate over the data loader to see the output\n","torch.manual_seed(0)\n","for label, text, offsets in train_loader:\n","    print(label, text, offsets)\n"]},{"cell_type":"markdown","metadata":{"id":"LcNLzN_D822C"},"source":["# <Font color = 'pickle'>**Embedding Bag Layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:38:10.427435Z","start_time":"2021-04-14T14:38:10.425166Z"},"id":"rNUrzBMDXvme"},"outputs":[],"source":["# Instantiating EmbeddingBag layer with total number of embeddings and dimension of embedding\n","# i.e. dimension of vector\n","\n","torch.manual_seed(0)\n","model = nn.EmbeddingBag(len(my_vocab), 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1695008087434,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"XSguAtiZxLZg","outputId":"91ff5702-7ac4-4d8f-b68e-831a14c6685d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487],\n","        [ 0.6920, -0.3160, -2.1152,  0.3223, -1.2633],\n","        [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168],\n","        [-0.2473, -1.3527, -1.6959,  0.5667,  0.7935],\n","        [ 0.5988, -1.5551, -0.3414,  1.8530, -0.2159],\n","        [-0.7425,  0.5627,  0.2596, -0.1740, -0.6787],\n","        [ 0.9383,  0.4889,  1.2032,  0.0845, -1.2001],\n","        [-0.0048, -0.5181, -0.3067, -1.5810,  1.7066]], requires_grad=True)"]},"metadata":{},"execution_count":68}],"source":["model.weight"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-04-14T14:39:24.851100Z","start_time":"2021-04-14T14:39:24.790405Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":191,"status":"ok","timestamp":1695008091317,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"1a2N3EffbbF-","outputId":"6d9cb11f-3579-477e-c354-d418e72d32c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Output\n","tensor([[ 0.5469, -0.5210, -0.7789,  1.1376, -0.1208],\n","        [ 0.1819,  0.4532,  0.5276,  0.3827, -0.2540]],\n","       grad_fn=<EmbeddingBagBackward0>)\n","torch.Size([2, 5])\n","===========================================================================\n","Output\n","tensor([[-0.1325,  0.1176,  0.0243, -0.1724,  0.7149],\n","        [ 0.2649, -0.4535, -1.2304,  0.7089,  0.2157]],\n","       grad_fn=<EmbeddingBagBackward0>)\n","torch.Size([2, 5])\n","===========================================================================\n"]}],"source":["for label, text, offsets in train_loader:\n","    output = model(text, offsets)\n","    print('Output')\n","    print(output)\n","    print(output.shape)\n","    print('='*75)"]},{"cell_type":"markdown","metadata":{"id":"tGbC6I4Awuo2"},"source":["---"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}