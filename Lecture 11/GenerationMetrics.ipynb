{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyML2aKm9MQQAzOsBXe418s6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"22e81d3062dc4b1e87a5f4fdd97d29ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e4d222bdf5244f7b0008e1c1832a396","IPY_MODEL_bba6f794b504407fb5af4ce6cf34f0f6","IPY_MODEL_29496fc9d48b45138139427952daec73"],"layout":"IPY_MODEL_059bdf95783e490d87c67357a326755a"}},"7e4d222bdf5244f7b0008e1c1832a396":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acef09cc8cea4e13af11f06ee13d6cc8","placeholder":"​","style":"IPY_MODEL_8c79b86861d84642b255e0fc8c5f2c62","value":"100%"}},"bba6f794b504407fb5af4ce6cf34f0f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a35d590b3254dff87f83d4d46132b97","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c81e15950e74eeca767ea56f577bc55","value":1}},"29496fc9d48b45138139427952daec73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d36e8096ef174b68a072df925e034d45","placeholder":"​","style":"IPY_MODEL_e6ed941bc2104fbcb507003d9de1148c","value":" 1/1 [00:00&lt;00:00,  4.65it/s]"}},"059bdf95783e490d87c67357a326755a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acef09cc8cea4e13af11f06ee13d6cc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c79b86861d84642b255e0fc8c5f2c62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a35d590b3254dff87f83d4d46132b97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c81e15950e74eeca767ea56f577bc55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d36e8096ef174b68a072df925e034d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ed941bc2104fbcb507003d9de1148c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4db4f26f7664659be10c43fca080164":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05eddccd9d9746e39af0f1ede8040c77","IPY_MODEL_20841b9427754cc0b2562991bfd1d7ad","IPY_MODEL_55c232172f494d3ba38955769a679d7a"],"layout":"IPY_MODEL_04f7492ccb4f40d78485a630c037f3d0"}},"05eddccd9d9746e39af0f1ede8040c77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e786fdcb140f4522b980cdcfc0b5567d","placeholder":"​","style":"IPY_MODEL_cd88f2e83ad749b78b343a18fae82a6c","value":"Downloading builder script: 100%"}},"20841b9427754cc0b2562991bfd1d7ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a0cb7f9dc824b5e8772ce0d6e4a253b","max":8482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9186a8b51f9f400f831637a585e01c65","value":8482}},"55c232172f494d3ba38955769a679d7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c4a5749ab7e4f36b9bedfced225c632","placeholder":"​","style":"IPY_MODEL_52f1ea36421545eb9608f408a03ec0f0","value":" 8.48k/8.48k [00:00&lt;00:00, 314kB/s]"}},"04f7492ccb4f40d78485a630c037f3d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e786fdcb140f4522b980cdcfc0b5567d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd88f2e83ad749b78b343a18fae82a6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a0cb7f9dc824b5e8772ce0d6e4a253b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9186a8b51f9f400f831637a585e01c65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c4a5749ab7e4f36b9bedfced225c632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52f1ea36421545eb9608f408a03ec0f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"351ad543fbee4718badb0aa419250dca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fc071b1c6c14513a6872f9d44af66f4","IPY_MODEL_126dabed02264b99804902ef7d51a2a7","IPY_MODEL_6b3edb9720814349a4aeeb6f4fc319e8"],"layout":"IPY_MODEL_030bd33d22f24e53af6d2667404a7b1c"}},"3fc071b1c6c14513a6872f9d44af66f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83bf48251f50409ea9aa3475505a878d","placeholder":"​","style":"IPY_MODEL_2d580f2a8282489d90a9e62687775e34","value":"Downloading metadata: 100%"}},"126dabed02264b99804902ef7d51a2a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd873d052e894d599d572cddf1d04e34","max":6838,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d1935ae98b34d5ba17afb9c3af4f951","value":6838}},"6b3edb9720814349a4aeeb6f4fc319e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b7c5495edc94cf0b00f3cfc9fcc594a","placeholder":"​","style":"IPY_MODEL_97aa09df123b4a9abc8d84927fc4263f","value":" 6.84k/6.84k [00:00&lt;00:00, 203kB/s]"}},"030bd33d22f24e53af6d2667404a7b1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83bf48251f50409ea9aa3475505a878d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d580f2a8282489d90a9e62687775e34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd873d052e894d599d572cddf1d04e34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d1935ae98b34d5ba17afb9c3af4f951":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b7c5495edc94cf0b00f3cfc9fcc594a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97aa09df123b4a9abc8d84927fc4263f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9385cd78af714e3d9e1b5604b6f5ef04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63317b0c034f43baaaf25edfec61225f","IPY_MODEL_d2c1d925238c45658e50d85be392873d","IPY_MODEL_81cd9f58f44e44349836f51822df85dd"],"layout":"IPY_MODEL_879d2838cb9b4faf99d5e3ca26859dfa"}},"63317b0c034f43baaaf25edfec61225f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa03aaebd14644fbb2602f73c9edd484","placeholder":"​","style":"IPY_MODEL_4d37cf63b16e46ee9e6648934380539e","value":"Downloading readme: 100%"}},"d2c1d925238c45658e50d85be392873d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c18adbb0eae54da78b95095a0c171ea7","max":9615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f25690b2d58410fb60db83f7af9f45a","value":9615}},"81cd9f58f44e44349836f51822df85dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33acd12206844a469d238b0ed0052c31","placeholder":"​","style":"IPY_MODEL_c950b1c8a5064d5d963234cfe127b0ed","value":" 9.62k/9.62k [00:00&lt;00:00, 309kB/s]"}},"879d2838cb9b4faf99d5e3ca26859dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa03aaebd14644fbb2602f73c9edd484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d37cf63b16e46ee9e6648934380539e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c18adbb0eae54da78b95095a0c171ea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f25690b2d58410fb60db83f7af9f45a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33acd12206844a469d238b0ed0052c31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c950b1c8a5064d5d963234cfe127b0ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1885d2c60c9a4860b4eb2f179a24aa09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d217925b90e842f4af8ed8704b612e96","IPY_MODEL_807b11bcbb47423c86d1404a97430655","IPY_MODEL_0410a32212254556b9b16c2dbacad666"],"layout":"IPY_MODEL_8a107d4fa373487eb00666dd06a6c053"}},"d217925b90e842f4af8ed8704b612e96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f00b8c9345ce494f922e34acd4ac9ae7","placeholder":"​","style":"IPY_MODEL_cbd03fed38f5457aa480eb9aac2ce422","value":"Downloading data: 100%"}},"807b11bcbb47423c86d1404a97430655":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe22ead29b97470d9c682ca0c9212b4b","max":4721645,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d75b59a0afc46bdbfd99e3080e2f526","value":4721645}},"0410a32212254556b9b16c2dbacad666":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4034da463e7c4dbbbe4d2a13a5a1a146","placeholder":"​","style":"IPY_MODEL_97669be6ca834b01a1e69729bc6ec38e","value":" 4.72M/4.72M [00:01&lt;00:00, 7.19MB/s]"}},"8a107d4fa373487eb00666dd06a6c053":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f00b8c9345ce494f922e34acd4ac9ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbd03fed38f5457aa480eb9aac2ce422":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe22ead29b97470d9c682ca0c9212b4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d75b59a0afc46bdbfd99e3080e2f526":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4034da463e7c4dbbbe4d2a13a5a1a146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97669be6ca834b01a1e69729bc6ec38e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3329d8747f6474aba7064471f1d556a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7f834e86d9341a0b3d2c8291f721de2","IPY_MODEL_da26483f73ed407b903dcbb808a7bb24","IPY_MODEL_b54f1f04dae346d49d85e5659a8baeca"],"layout":"IPY_MODEL_f0d8716202e64251a3102e8e89b1bcce"}},"c7f834e86d9341a0b3d2c8291f721de2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e4b5c7b6ce6426faac5398ae0f2160b","placeholder":"​","style":"IPY_MODEL_76bb00d9c9464600a34ad648d7b14670","value":"Generating test split: 100%"}},"da26483f73ed407b903dcbb808a7bb24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a70ba933da40d5967441e4a1037960","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c5acef06b694e77b40d60726626d3c7","value":4358}},"b54f1f04dae346d49d85e5659a8baeca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_345ec05edc4249c7bcac0467500714f8","placeholder":"​","style":"IPY_MODEL_96bf466910744b0c8461b5093deb490f","value":" 4358/4358 [00:00&lt;00:00, 15915.53 examples/s]"}},"f0d8716202e64251a3102e8e89b1bcce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e4b5c7b6ce6426faac5398ae0f2160b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76bb00d9c9464600a34ad648d7b14670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04a70ba933da40d5967441e4a1037960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c5acef06b694e77b40d60726626d3c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"345ec05edc4249c7bcac0467500714f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96bf466910744b0c8461b5093deb490f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e574456505d45b78ebea14240a1d272":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79dc3993a33b44d68ef4943e0ab0edb9","IPY_MODEL_53cfc9b2b1fb405eb9ae7f9f882dd783","IPY_MODEL_bde5f9cff59745d48ff211aba47b6dbe"],"layout":"IPY_MODEL_0811071e1e1b41269199607ce1c3ac98"}},"79dc3993a33b44d68ef4943e0ab0edb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f49a1e3c9e2402bb1fc80c99f88bda0","placeholder":"​","style":"IPY_MODEL_82df8c51139240f5b87913474c95031d","value":"Generating train split: 100%"}},"53cfc9b2b1fb405eb9ae7f9f882dd783":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c891db6499b844ff9970b3a62d4abfb6","max":36718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26951e0317bc46ff91a163ee8f851376","value":36718}},"bde5f9cff59745d48ff211aba47b6dbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b249748bfb4683be13f4be52cac85c","placeholder":"​","style":"IPY_MODEL_b036bd20a2a5445ba0ef3ce38ee5fc53","value":" 36718/36718 [00:01&lt;00:00, 21961.10 examples/s]"}},"0811071e1e1b41269199607ce1c3ac98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f49a1e3c9e2402bb1fc80c99f88bda0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82df8c51139240f5b87913474c95031d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c891db6499b844ff9970b3a62d4abfb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26951e0317bc46ff91a163ee8f851376":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02b249748bfb4683be13f4be52cac85c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b036bd20a2a5445ba0ef3ce38ee5fc53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa9325bde205464090d16637fa69e50a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_936bcdc27c524916852b9ee32e4b33c5","IPY_MODEL_665cee95e627490880976914414e2cee","IPY_MODEL_232416148fa34dc19287d4bb7b416abe"],"layout":"IPY_MODEL_1b19f62ced5e470d8da9024cc6b31b62"}},"936bcdc27c524916852b9ee32e4b33c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_771e0c7839134bc5a23bcbad7347416a","placeholder":"​","style":"IPY_MODEL_a5976adf8cdb47afb27a1455d7478615","value":"Generating validation split: 100%"}},"665cee95e627490880976914414e2cee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c40a59893f654e70b841a9691dd3d51e","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_505e0156c9b345d38a32783f2d550c01","value":3760}},"232416148fa34dc19287d4bb7b416abe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b8feb84ea8646aca42ac97a63951630","placeholder":"​","style":"IPY_MODEL_8beb5b0ee7e44174ac382f09a253661d","value":" 3760/3760 [00:00&lt;00:00, 14460.45 examples/s]"}},"1b19f62ced5e470d8da9024cc6b31b62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"771e0c7839134bc5a23bcbad7347416a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5976adf8cdb47afb27a1455d7478615":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c40a59893f654e70b841a9691dd3d51e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"505e0156c9b345d38a32783f2d550c01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b8feb84ea8646aca42ac97a63951630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8beb5b0ee7e44174ac382f09a253661d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f6051419035491890be90f653f3c1ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e72a7154fd4c42e0a8845571c672f14b","IPY_MODEL_7d2c0b91f2e04b6381f323637f7d80af","IPY_MODEL_dd7918f6992c4d41a61e3fb52a372199"],"layout":"IPY_MODEL_0903881cc50440b7a27d19b7a5717da6"}},"e72a7154fd4c42e0a8845571c672f14b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_739cea9d481d4b619da3e3738efd75c6","placeholder":"​","style":"IPY_MODEL_4b023179ce274a93848e25753b40f1d3","value":"100%"}},"7d2c0b91f2e04b6381f323637f7d80af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ef0c880b1c24115a684889b575011e6","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6993a1abd6db4a309cd2b88ebf8b30ba","value":2}},"dd7918f6992c4d41a61e3fb52a372199":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ee5095ab8194b99b111befff7e4cb39","placeholder":"​","style":"IPY_MODEL_b02c32be97a846e5be41264bf025a613","value":" 2/2 [00:45&lt;00:00, 21.84s/it]"}},"0903881cc50440b7a27d19b7a5717da6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"739cea9d481d4b619da3e3738efd75c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b023179ce274a93848e25753b40f1d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ef0c880b1c24115a684889b575011e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6993a1abd6db4a309cd2b88ebf8b30ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ee5095ab8194b99b111befff7e4cb39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b02c32be97a846e5be41264bf025a613":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ca0a7e587f344d5aaaccadbd24a7e76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da559214910c4b35bef5afd28fd58710","IPY_MODEL_f9a29477cd4b4c59bc092fd4389cb344","IPY_MODEL_f8c42586dc584a41bfd539c82cec795e"],"layout":"IPY_MODEL_e469737193f843488fa234a0de767572"}},"da559214910c4b35bef5afd28fd58710":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d69d641bd3cb4c2aa46e7f50996a047e","placeholder":"​","style":"IPY_MODEL_cc100927a28f45acbc1ac0709f1fe2a7","value":"Downloading builder script: 100%"}},"f9a29477cd4b4c59bc092fd4389cb344":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fefaacd786640dc9885813795aab48f","max":6927,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06d46686d7a64c06b81fca275a836aba","value":6927}},"f8c42586dc584a41bfd539c82cec795e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22516092ef9e417dbea6f8647898ab49","placeholder":"​","style":"IPY_MODEL_fe87ddb560d4444eb26a161363ec600f","value":" 6.93k/6.93k [00:00&lt;00:00, 150kB/s]"}},"e469737193f843488fa234a0de767572":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d69d641bd3cb4c2aa46e7f50996a047e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc100927a28f45acbc1ac0709f1fe2a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fefaacd786640dc9885813795aab48f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06d46686d7a64c06b81fca275a836aba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22516092ef9e417dbea6f8647898ab49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe87ddb560d4444eb26a161363ec600f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["\n","# Introduction\n","\n","## Overview of NLP Generative Tasks\n","\n","Natural Language Processing (NLP) has seen rapid advancements, leading to the development of various generative tasks. These tasks involve the creation of new text based on certain inputs and contexts. They are pivotal in applications such as chatbots, automated content creation, and language translation. The primary generative tasks we will focus on in this tutorial include:\n","\n","1. **Text Generation**: This involves automatically generating coherent and contextually relevant text based on a given input. Examples include story generation, content completion, and automated journalism.\n","\n","2. **Abstractive Summarization**: Unlike extractive summarization which pulls key phrases or sentences directly from the source, abstractive summarization aims to capture the essence of the source material and express it in new, concise terms. This task is crucial in creating summaries for lengthy documents like articles or reports.\n","\n","3. **Abstractive Question Answering**: This task involves understanding a query posed in natural language and generating an answer that is not necessarily a verbatim segment from the source text. It requires deep comprehension and the ability to generate relevant, accurate responses.\n","\n","## The Role of Metrics in NLP Model Evaluation\n","\n","Evaluating the performance of models that handle these generative tasks is not straightforward. Unlike tasks with clear right or wrong answers (such as classification), generative tasks require an assessment of aspects like fluency, coherence, relevance, and factual accuracy of the generated text. This is where metrics come in. They provide a way to quantitatively measure the performance of NLP models, offering insights into aspects such as:\n","\n","- **Quality**: How well does the generated text align with human standards of language quality?\n","- **Relevance**: Does the output adequately respond to the input prompt or question?\n","- **Coherence**: Is the generated text logically structured and understandable?\n","- **Diversity**: Does the model produce varied and unique outputs, or does it tend to generate repetitive responses?\n","\n","In this tutorial, we will delve into several key metrics used to evaluate NLP generative tasks, understand how they work, and learn how to implement them using Python in a Jupyter Notebook environment.\n","\n","---\n","\n","This section sets the stage for your tutorial by providing an introduction to NLP generative tasks and the importance of metrics in their evaluation. It gives context to the learners about what they can expect to learn and why it's important."],"metadata":{"id":"vtpS5C5xV-eU"}},{"cell_type":"markdown","source":["# Setting Up the Jupyter Notebook Environment\n","\n","To effectively work through the examples and code in this tutorial, it's essential to have a properly set up Jupyter Notebook environment. This section will guide you through the process of installing necessary libraries and setting up your Jupyter Notebook."],"metadata":{"id":"qLbTxpdJaeMR"}},{"cell_type":"markdown","source":["## Installing Necessary Libraries"],"metadata":{"id":"L7Ychtc1bJvE"}},{"cell_type":"code","source":["!pip install transformers evaluate rouge_score datasets bert_score -qq"],"metadata":{"id":"FSKMy8bjbO51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699744908225,"user_tz":360,"elapsed":12534,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"52e6232b-41d4-41ce-af88-aa2c14f8ba91"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/61.1 kB\u001b[0m \u001b[31m742.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m961.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Importing Libraries in Jupyter Notebook"],"metadata":{"id":"eO4tTTnlbMh2"}},{"cell_type":"code","source":["import nltk\n","import evaluate\n","import datasets\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","import scipy\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"GJ8lVjihbhbn","executionInfo":{"status":"ok","timestamp":1699734530168,"user_tz":360,"elapsed":241,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["# Basics of NLP Generative Tasks\n","\n","In this section, we will briefly introduce the core NLP generative tasks - Text Generation, Abstractive Summarization, Abstractive Question Answering, and Machine Translation. Understanding these tasks is crucial before we dive into the metrics used to evaluate them.\n","\n","## Text Generation\n","\n","Text Generation in NLP involves creating meaningful and coherent text automatically. This task has a wide range of applications, from generating creative stories to producing news articles. The key challenge is to ensure that the generated text is relevant, coherent, and contextually appropriate.\n","\n","## Abstractive Summarization\n","\n","Abstractive Summarization aims to produce a concise and fluent summary of a longer text. Unlike extractive summarization, which merely selects parts of the source text, abstractive summarization generates new phrases, possibly rephrasing or using new words, to convey the main points of the original text. It's vital in digesting long articles, reports, or even books into shorter, consumable content.\n","\n","## Abstractive Question Answering\n","\n","Abstractive Question Answering systems understand a query in natural language and generate a response that directly answers the question. This response is not a mere extraction from a given text but an abstraction, demonstrating an understanding of both the question and the relevant knowledge base or text.\n","\n","## Machine Translation\n","\n","Machine Translation is the task of automatically converting text from one language to another. This task is challenging due to the complexity of accurately capturing the meaning and nuances of the original text and translating them into a different language while maintaining fluency and coherence. Applications include translating web pages, documents, or even real-time translation in communication apps.\n","\n","## Importance of These Tasks\n","\n","These generative tasks play a crucial role in various applications, from enhancing user experience in AI-driven interfaces to providing critical information in accessible formats. As the demand for sophisticated NLP applications grows, the need for effective and accurate generative models becomes increasingly important.\n","\n","In the following sections, we will explore various metrics used to evaluate these tasks. Understanding these metrics will help us gauge the performance of NLP models in generating human-like, coherent, and contextually relevant text.\n","\n","---\n"],"metadata":{"id":"nu3tnCRubf2K"}},{"cell_type":"markdown","source":["# Comprehensive Overview of Evaluation Metrics\n","\n","Evaluating NLP generative tasks requires a set of metrics that can quantitatively measure various aspects of the generated text. In this section, we will introduce a range of metrics, each providing unique insights into the performance of NLP models. Later, we will explore each metric in detail, including their implementation using the latest libraries from Hugging Face and interpreting their outputs.\n","\n","## Overview of Key Metrics\n","\n","1. **BLEU (Bilingual Evaluation Understudy)**: Primarily used in Machine Translation, BLEU measures how many words and phrases in the generated text match a reference text, focusing on precision.\n","\n","2. **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: Commonly used in summarization tasks, ROUGE evaluates the quality of summary by measuring the overlap of n-grams between the generated summary and a reference summary.\n","\n","3. **Perplexity**: Often used in text generation, perplexity measures how well a probability model predicts a sample. It gauges the uncertainty of the language model about the generated text.\n","\n","4. **METEOR (Metric for Evaluation of Translation with Explicit Ordering)**: Similar to BLEU but with improved correlation with human judgment, METEOR considers word order and synonym matching in translation.\n","\n","5. **BERTScore**: Utilizing BERT embeddings, this metric compares the semantic similarity between the generated text and the reference text, offering a more nuanced evaluation than n-gram matching.\n","\n","\n","In the following subsections, we will explore each of these metrics in detail. We will discuss how they work, how to implement them using Python and Hugging Face libraries, and how to interpret their outputs to effectively evaluate NLP models.\n","\n","\n","\n"],"metadata":{"id":"kOeL3Fltb-Na"}},{"cell_type":"markdown","source":["# BLEU Metric"],"metadata":{"id":"_2icW98PkLyu"}},{"cell_type":"markdown","source":["## Understanding Clipped Precision and Brevity Penalty\n","\n","## Clipped Precision vs. Regular Precision\n","\n","Clipped precision is crucial in the BLEU metric to prevent models from getting undue credit for repeated words. Let's look at an example to understand the difference between regular precision and clipped precision.\n","\n","### Example to Illustrate Clipped Precision\n","\n","- **Reference Translation**: \"the quick brown fox jumps over the lazy dog\"\n","- **Machine Translation**: \"the the the the the the the the the\"\n","\n","#### Regular Precision Calculation\n","- Total unigrams in Machine Translation: 9\n","- Unigram matches in Reference: 9 (naively counting \"the\")\n","- Regular Precision = (Number of Unigram Matches) / (Total Unigrams in Machine Translation) = 9 / 9 = 1.0\n","\n","#### Clipped Precision Calculation\n","- \"The\" appears only once in the Reference.\n","- Clipped count for \"the\" = 2 (not 9)\n","- Clipped Precision = 2 / 9 ≈ 0.22\n","\n","The clipped precision significantly lowers the score, reflecting a more accurate evaluation of the translation quality.\n","\n","## Brevity Penalty\n","\n","The brevity penalty is applied when the machine translation is shorter than the reference translation.\n","\n","### Example of Brevity Penalty\n","\n","- **Reference Translation**: \"The quick brown fox jumps over the lazy dog\"\n","- **Machine Translation**: \"A quick fox\"\n","\n","#### Brevity Penalty Calculation\n","- Length of Machine Translation: 3\n","- Length of Reference Translation: 9\n","- Brevity Penalty is applied since the machine translation is shorter.\n","\n","## Python Implementation using Hugging Face's `evaluate`\n","To calculate the BLEU score with the `evaluate` library from Hugging Face, use the following Python code:"],"metadata":{"id":"39hSA5XnyDSY"}},{"cell_type":"code","source":["from evaluate import load\n","\n","bleu_metric = load(\"bleu\")\n","\n","reference = [\"The quick brown fox jumps over the lazy dog\"]\n","candidate = [\"The quick brown fox jumped over the lazy dog\"]\n","\n","result = bleu_metric.compute(predictions=candidate, references=reference, max_order = 1)\n","result"],"metadata":{"id":"PyoLzPm4lyyS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699725320637,"user_tz":360,"elapsed":3166,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"6dea6aa1-213f-4b51-ab82-8d0242c6e184"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bleu': 0.8888888888888888,\n"," 'precisions': [0.8888888888888888],\n"," 'brevity_penalty': 1.0,\n"," 'length_ratio': 1.0,\n"," 'translation_length': 9,\n"," 'reference_length': 9}"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["## BLEU equations\n","\n","Brevity Penalty (BP):\n","\n","$$\n","BP =\n","\\begin{cases}\n","1 & \\text{if } c > r \\\\\n","e^{(1-r/c)} & \\text{if } c \\leq r\n","\\end{cases}\n","$$\n","\n","Then, the BLEU score is calculated as:\n","\n","$$\n","BLEU = BP \\cdot \\exp\\left(\\sum_{n=1}^{N} w_n \\log P_n\\right)\n","$$\n","\n","In the baseline, where $( N = 4)$ and uniform weights $( w_n = \\frac{1}{N} )$ are used.\n"],"metadata":{"id":"puUMXbq6giZ-"}},{"cell_type":"code","source":["result = bleu_metric.compute(predictions=candidate, references=reference, max_order = 4)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDuAe3aUo6Ud","executionInfo":{"status":"ok","timestamp":1699725324297,"user_tz":360,"elapsed":322,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"4efb1eba-d505-4d97-c405-132047b75229"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bleu': 0.5969491792019646,\n"," 'precisions': [0.8888888888888888,\n","  0.75,\n","  0.5714285714285714,\n","  0.3333333333333333],\n"," 'brevity_penalty': 1.0,\n"," 'length_ratio': 1.0,\n"," 'translation_length': 9,\n"," 'reference_length': 9}"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["np.exp(np.sum(1/4 * np.log(result['precisions'])))"],"metadata":{"id":"ruJS3Ncplvam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699725542278,"user_tz":360,"elapsed":253,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"4beb52ff-b786-4e66-a170-3ac6e2bb0976"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5969491792019646"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["## BLEU Metric Example for the whole document\n","\n","When calculating the BLEU score for an entire document with one reference per prediction, you'll follow these steps:\n","\n","### 1. Tokenize Predictions and References\n","   - Break down each sentence in the predictions and references into individual words (tokens).\n","\n","### 2. Count Matches and Clip Counts\n","   - For each prediction-reference pair:\n","     - Count the occurrences of each unigram (word) in the prediction.\n","     - Count the occurrences of each unigram in the corresponding reference.\n","     - Clip the count of each unigram in the prediction to the count in the reference. This means if a unigram appears more in the prediction than in the reference, its count is reduced to match the reference count.\n","\n","### 3. Calculate Clipped Precision\n","   - Sum the clipped counts for all predictions.\n","   - Divide this sum by the total number of unigrams across all predictions. This gives the proportion of unigrams in the predictions that are correctly predicted, according to the references.\n","\n","### 4. Calculate Total Lengths\n","   - Compute the total length of the predictions (sum of the number of unigrams in all predictions).\n","   - Compute the total length of the references (sum of the number of unigrams in each reference, using the length of the single reference for each prediction).\n","\n","### 5. Calculate Brevity Penalty\n","   - The brevity penalty compensates for the tendency of shorter translations to have higher precision. It's calculated using the ratio of the total length of the translations to the total length of the references.\n","   - If the total length of the translations is less than the total length of the references, the brevity penalty is less than 1, reducing the BLEU score. Otherwise, it is 1 (no penalty).\n","\n","### 6. Compute BLEU Score\n","   - Multiply the clipped precision by the brevity penalty to get the final BLEU score.\n","\n","### 7. Interpret the Score\n","   - A higher BLEU score indicates better translation quality, with a score of 1 being perfect (an exact match with the references).\n","\n","In summary, the BLEU score calculation involves a detailed comparison of the translated text against reference translations at the unigram level, considering both accuracy (through precision) and fluency (through the brevity penalty). This method provides a quantitative measure of translation quality for the entire document."],"metadata":{"id":"NL73h-RcWbez"}},{"cell_type":"code","source":["from evaluate import load\n","\n","bleu = load(\"bleu\")\n","\n","predictions = [\"The fast brown fox jumps over the lazy dog\",\n","    \"A speedy fox jumps over a dog\"]\n","\n","references = [\n","    [\"The swift brown fox leaps over the lazy dog\"],\n","    [\"The quick brown fox jumps over the lazy dog\"]\n","  ]\n","\n","\n","results = bleu.compute(predictions=predictions, references=references, max_order =1)\n","\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZXPReSDX6BE","executionInfo":{"status":"ok","timestamp":1699722805282,"user_tz":360,"elapsed":4092,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"5c09cb4c-3ee8-4d9b-fb38-4b0c19fe3e66"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bleu': 0.6067166205269093,\n"," 'precisions': [0.6875],\n"," 'brevity_penalty': 0.8824969025845955,\n"," 'length_ratio': 0.8888888888888888,\n"," 'translation_length': 16,\n"," 'reference_length': 18}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import math\n","from collections import Counter\n","\n","# Define the predictions and references\n","predictions = [\"the fast brown fox jumps over the lazy dog\", \"a speedy fox jumps over a dog\"]\n","references = [\n","    [\"the swift brown fox leaps over the lazy dog\"],\n","    [\"the quick brown fox jumps over the lazy dog\"]\n","]\n","\n","# Step 1: Tokenize Predictions and References\n","tokenized_predictions_manual = [p.split() for p in predictions]\n","tokenized_references_manual = [[r.split() for r in group] for group in references]\n","\n","# Step 2 & 3: Count Matches and Clip Counts\n","matches = 0\n","for pred, refs in zip(tokenized_predictions_manual, tokenized_references_manual):\n","    pred_counter = Counter(pred)\n","    ref_counter = Counter(refs[0])  # Use the single reference\n","    print(pred_counter)\n","    print(ref_counter)\n","    print(\"------------------------------\")\n","    matches += sum(min(pred_counter[unigram], ref_counter[unigram]) for unigram in pred_counter)\n","\n","# Step 4: Calculate Clipped Precision\n","total_unigrams_in_predictions = sum(len(p) for p in tokenized_predictions_manual)\n","clipped_precision_manual = matches / total_unigrams_in_predictions\n","\n","# Step 5: Calculate Total Lengths\n","total_translation_length = total_unigrams_in_predictions\n","total_reference_length = sum(len(r[0]) for r in tokenized_references_manual)  # Use the length of the single reference\n","\n","# Step 6: Calculate Brevity Penalty\n","length_ratio = total_translation_length / total_reference_length\n","brevity_penalty_manual = math.exp(1 - 1 / length_ratio) if length_ratio < 1 else 1.0\n","\n","# Step 7: Compute BLEU Score\n","bleu_score_manual = clipped_precision_manual * brevity_penalty_manual\n","\n","# Final BLEU Score and components\n","bleu_score_manual, clipped_precision_manual, brevity_penalty_manual, length_ratio\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i45pduiNyzBN","executionInfo":{"status":"ok","timestamp":1699722859361,"user_tz":360,"elapsed":254,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"0d14e451-f36e-44d7-f88a-2ac7da65d7c9"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({'the': 2, 'fast': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1})\n","Counter({'the': 2, 'swift': 1, 'brown': 1, 'fox': 1, 'leaps': 1, 'over': 1, 'lazy': 1, 'dog': 1})\n","------------------------------\n","Counter({'a': 2, 'speedy': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'dog': 1})\n","Counter({'the': 2, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1})\n","------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6067166205269093, 0.6875, 0.8824969025845955, 0.8888888888888888)"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## Extended BLEU Metric Example with Multiple References\n","\n","## Scenario Setup\n","\n","We're evaluating two machine translations, each with a different set of reference translations.\n","\n","### Translation 1\n","- **Machine Translation 1**: \"The fast brown fox jumps over the lazy dog\"\n","- **Reference Translations**:\n","  - Reference 1: \"The quick brown fox jumps over the lazy dog\"\n","  - Reference 2: \"The swift brown fox leaps over the lazy dog\"\n","\n","### Translation 2\n","- **Machine Translation 2**: \"A speedy fox jumps over a dog\"\n","- **Reference Translation**:\n","  - Reference: \"The quick brown fox jumps over the lazy dog\"\n","\n","\n","### Reference Counts for Each Token:\n","- **Maximum Count Across References:** For each unigram (or n-gram) in the prediction, you determine its count in each reference and then take the maximum of these counts. This method accounts for the possibility that different references might have varying frequencies of the same word.\n","- **Example:** If \"the\" appears 2 times in one reference and 3 times in another, you would use 3 as its count for clipping. Similarly, if \"fox\" appears 1 time in one reference and 2 times in another, you would use 2 for its count.\n","\n","### Clipping Counts:\n","- The count of each unigram in the prediction is clipped to this maximum count found across all references. This approach ensures fairness by considering all possible valid translations represented in the references.\n","\n","### Brevity Penalty:\n","- **Length of Shortest References:** For calculating the brevity penalty, the BLEU score uses the length of the shortest reference for each prediction. This choice is made to avoid unfairly penalizing the translation for being shorter than unnecessarily long reference translations.\n","- **Penalty Calculation:** The brevity penalty is calculated based on the ratio of the total length of the translations to the total length of these shortest references. If the translations are shorter, the penalty reduces the BLEU score, balancing precision with adequate translation length.\n","\n","In summary, handling multiple references per prediction in BLEU score calculation involves taking the maximum count of each unigram across all references and using the shortest reference length for calculating the brevity penalty. This approach ensures a balanced and fair assessment of translation quality, accommodating the diversity in possible correct translations."],"metadata":{"id":"aA_3WfTcpiPi"}},{"cell_type":"code","source":["from evaluate import load\n","\n","bleu = load(\"bleu\")\n","\n","predictions = [\"the fast brown fox jumps over the lazy dog\",\n","    \"a speedy fox jumps over a dog\"]\n","\n","references = [\n","    [[\"the quick brown fox jumps over the lazy dog\"],\n","     [\"the swift brown fox leaps over the lazy dog\"]],\n","    [[\"the quick brown fox jumps over the lazy dog\"]]\n","]\n","\n","results = bleu.compute(predictions=predictions, references=references, max_order=1)\n","\n","results\n"],"metadata":{"id":"RPLX6e54qwpA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699723705499,"user_tz":360,"elapsed":4280,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"ac34756f-9280-47c1-d02f-5252ffbb694b"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bleu': 0.3866002193199219,\n"," 'precisions': [0.5625],\n"," 'brevity_penalty': 0.6872892787909722,\n"," 'length_ratio': 0.7272727272727273,\n"," 'translation_length': 16,\n"," 'reference_length': 22}"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["## Limitations and Bias of BLEU Metric:\n","\n","1. **Focus on Token Overlap, Not Meaning**: BLEU primarily assesses the similarity in tokens between the predicted and reference texts, rather than their semantic equivalence. This can lead to situations where BLEU scores do not align with human judgments of translation quality, as humans consider the conveyed meaning rather than just token matching.\n","\n","2. **Bias Towards Shorter Translations**: The way BLEU is calculated inherently favors shorter translations, which may achieve higher scores due to their token overlap structure. To mitigate this, a brevity penalty is implemented, but this is only a partial solution.\n","\n","3. **Lack of Comparability Across Datasets and Languages**: BLEU scores are not universally comparable. They can vary significantly when applied to different datasets or languages, making it difficult to use BLEU for standardized cross-context comparisons.\n","\n","4. **Sensitivity to Parameters and Techniques Used**: The BLEU score is highly sensitive to the specific parameters and techniques used in its computation, such as tokenization methods and normalization processes. This sensitivity means that BLEU scores calculated with different sets of parameters or techniques are not directly comparable. This aspect is further discussed in related literature and debates surrounding the metric's application."],"metadata":{"id":"fndxFLadx6VS"}},{"cell_type":"markdown","source":["# ROUGE Metric\n","\n","## Overview of ROUGE\n","\n","ROUGE stands for **R**ecall-**O**riented **U**nderstudy for **G**isting **E**valuation. It is a collection of metrics used for evaluating text summarization and machine translation. ROUGE measures the overlap of content between generated text and reference texts, emphasizing capturing significant content.\n","\n","### ROUGE Variants\n","- **ROUGE-N**: Measures n-gram overlap (unigrams, bigrams, trigrams) between generated text and reference.\n","- **ROUGE-L**: Focuses on the longest common subsequence (LCS) between the texts.\n","- **ROUGE-Lsum**: Similar to ROUGE-L, but applies LCS calculation sentence-by-sentence.\n","\n","\n","## Detailed Example and Calculation\n","### **Scenario**\n","**Predictions:**<br>\n","\"police kill the gunman\"<br>\n","\"the gunman kill police\"<br>\n","\"the gunman police killed\"<br>\n","\n","**References** (all three are the same): \"police killed the gunman\"\n","\n","### ROUGE-1 (Unigram Overlap)\n","For each prediction, we will calculate the number of matching unigrams with the reference:\n","\n","- **Reference Summary**: [\"police\", \"killed\", \"the\", \"gunman\"]\n","- **Prediction 1**: [\"police\", \"kill\", \"the\", \"gunman\"] - 3 matches (\"police\", \"the\", \"gunman\")\n","- **Prediction 2**: [\"the\", \"gunman\", \"kill\", \"police\"] - 3 matches (\"the\", \"gunman\", \"police\")\n","- **Prediction 3**: [\"the\", \"gunman\", \"police\", \"killed\"] - 4 matches (\"the\", \"gunman\", \"police\", \"killed\")\n","\n","Now, let's calculate the ROUGE-1 scores:\n","\n","- **ROUGE-1 Recall**: Number of Matching Unigrams / Total Unigrams in Reference\n","  - For Prediction 1 and 2: 3 / 4 = 0.75\n","  - For Prediction 3: 4 / 4 = 1.0\n","- **ROUGE-1 Precision**: Number of Matching Unigrams / Total Unigrams in Prediction\n","  - For Prediction 1 and 2: 3 / 4 = 0.75\n","  - For Prediction 3: 4 / 4 = 1.0\n","- **ROUGE-1 F1 Score**:\n","$$F1 = 2 \\times \\frac{{\\text{Precision} \\times \\text{Recall}}}{{\\text{Precision} + \\text{Recall}}}$$\n","\n","  - The harmonic mean of precision and recall: **[0.75, 0.75, 1]**\n","\n","### ROUGE-2 (Bigram Overlap)\n","Now for bigrams:\n","\n","- **Reference Summary Bigrams**: [\"police killed\", \"killed the\", \"the gunman\"]\n","- **Prediction 1 Bigrams**: [\"police kill\", \"kill the\", \"the gunman\"] - 1 match (\"the gunman\")\n","- **Prediction 2 Bigrams**: [\"the gunman\", \"gunman kill\", \"kill police\"] - 1 match (\"the gunman\")\n","- **Prediction 3 Bigrams**: [\"the gunman\", \"gunman police\", \"police killed\"] - 2 match (\"the gunman\", \"police killed\")\n","\n","- **ROUGE-2 Recall**: Number of Matching Bigrams / Total Bigrams in Reference\n","  - For Prediction 1 and 2: 1 / 3 = 0.33\n","  - For Prediction 3: 2 / 3 = 0.66\n","- **ROUGE-2 Precision**: Number of Matching Bigrams / Total Bigrams in Prediction\n","  - For Prediction 1 and 2: 1 / 3 = 0.33\n","  - For Prediction 3: 2 / 3 = 0.66\n","- **ROUGE-2 F1 Score**: The harmonic mean of precision and recall: **[0.33, 0.33. 0.66]**\n","\n","### ROUGE-L (Longest Common Subsequence): Sentence Level LCS\n","We will demonstarte the the calculations for each sentence separately.\n","\n","ROUGE-L is based on the longest common subsequence.\n","\n","- **LCS for Prediction 1**: \"police ... the gunman\", **Length of LCS = 3**\n","- **LCS for Prediction 2**: \"the gunman\", **Length of LCS = 2**\n","- **LCS for Prediction 3**: \"the gunman\" AND \"police killed\", **Length of LCS = 2**\n","\n","- **ROUGE-L Recall**: Length of LCS / Total Words in Reference\n","  - For Prediction 1: 1 / 3 = 3/4 = 0.75\n","  - For Prediction 2 and 3: 2 / 4 = 0.5\n","- **ROUGE-L Precision**: Length of LCS / Total Words in Prediction\n","  - For Prediction 1: 1 / 3 = 3/4 = 0.75\n","  - For Prediction 2 and 3: 2 / 4 = 0.5\n","- **ROUGE-L F1 Score**: The harmonic mean of precision and recall : **[0.75, 0.5, 0.5]**\n","\n","\n","\n"],"metadata":{"id":"v3r2Wkgmx89U"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Define a simple whitespace tokenizer function\n","def whitespace_tokenizer(text):\n","    return text.split()\n","\n","# Load ROUGE metric\n","rouge = load(\"rouge\")\n","\n","# Define predictions and references\n","predictions = [\"police kill the gunman\", \"the gunman kill police\", \"the gunman police killed\"]\n","references = [\"police killed the gunman\", \"police killed the gunman\", \"police killed the gunman\"]\n","\n","# Compute ROUGE scores using the custom whitespace tokenizer\n","results = rouge.compute(predictions=predictions, references=references, tokenizer=whitespace_tokenizer,\n","                        use_stemmer=False, use_aggregator = False)\n","print(\"Detailed ROUGE Score:\")\n","results"],"metadata":{"id":"vpKYm05PyrPr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699678559685,"user_tz":360,"elapsed":926,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"143faa06-8784-4914-deeb-7bd07ec74114"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Detailed ROUGE Score:\n"]},{"output_type":"execute_result","data":{"text/plain":["{'rouge1': [0.75, 0.75, 1.0],\n"," 'rouge2': [0.3333333333333333, 0.3333333333333333, 0.6666666666666666],\n"," 'rougeL': [0.75, 0.5, 0.5],\n"," 'rougeLsum': [0.75, 0.5, 0.5]}"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["In the above example we only have one sentence foir each prediction, rougeL and rougeLSum are same"],"metadata":{"id":"vrtpAEBNxA4o"}},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UidvTD8QvICJ","executionInfo":{"status":"ok","timestamp":1699678571825,"user_tz":360,"elapsed":1272,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"e5df2e18-9348-4c3e-f644-c0ed80afb219"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["Detailed ROUGE Score:\n","{'rouge1': 0.8333333333333334, 'rouge2': 0.4444444444444444, 'rougeL': 0.5833333333333334, 'rougeLsum': 0.5833333333333334}\n"]}]},{"cell_type":"markdown","source":["This code computes the ROUGE score for our example. The output includes various components such as ROUGE-N, ROUGE-L, and ROUGE-S scores, providing a comprehensive view of the summarization quality."],"metadata":{"id":"P0dGEoITyuaj"}},{"cell_type":"markdown","source":["\n","\n","## Limitations and Considerations\n","- **Focus on Overlap**: Like BLEU, ROUGE primarily measures overlap in tokens, which may not fully capture the semantic accuracy and coherence of the generated text.\n","- **Greater Emphasis on Recall**: ROUGE emphasizes content coverage from the reference in the generated text, which can sometimes overlook the conciseness and relevance aspects of a good summary.\n","- **Variability with Reference Quality**: The effectiveness of ROUGE is heavily dependent on the quality and representativeness of the reference summaries.\n","- **Sensitivity to Text Preprocessing**: Similar to BLEU, ROUGE scores can be influenced by the text preprocessing techniques used, such as tokenization and stemming.\n","\n","---\n","\n","This section provides a foundational understanding of the ROUGE metric with an example and a Python code implementation using Hugging Face's `evaluate` library. It offers insights into the metric's application in evaluating text summarization and the nuances involved in its interpretation."],"metadata":{"id":"YQUtCGi8vDP-"}},{"cell_type":"markdown","source":["# Perplexity\n","\n","### Perplexity\n","\n","Perplexity is a measurement that determines how well a probability distribution or a probability model predicts a sample. It is commonly used in natural language processing to gauge the effectiveness of language models, representing the average likelihood of a sequence of words appearing in the model's training data. Lower perplexity indicates that the model predictions are closer to the actual distribution of the words in the sequence.\n","\n","### Connection to Cross-Entropy Loss\n","\n","Perplexity is intrinsically related to the cross-entropy loss function, which is a standard objective for training language models:\n","\n","- **Cross-Entropy Loss**: During the training of a language model, the cross-entropy loss function evaluates the quality of the model's predictions. It does so by calculating the negative log-likelihood of the predicted probability distribution against the actual distribution of words in the training data. For a given sequence of words $( w_1, w_2, ..., w_N )$, the loss is computed as:\n","\n","$$L = -\\frac{1}{N} \\sum_{i=1}^{N} \\log p(w_i | w_1, ..., w_{i-1})$$\n","\n","Here, $p(w_i | w_1, ..., w_{i-1})$ is the probability assigned by the model to the actual word $ w_i$, given the preceding words in the sequence.\n","\n","- **Perplexity Calculation**: Perplexity is defined as the exponential of the average cross-entropy loss across a dataset. If the base of the logarithm in the loss function is \\( e \\), then the perplexity is directly the exponentiation of the loss:\n","\n","$$ \\text{Perplexity} = e^{L}$$\n","\n","This relationship means that a model with lower cross-entropy loss will have lower perplexity, indicating that the model's predictions are more accurate or 'surprising' less often. In essence, perplexity can be understood as a measure of uncertainty in the model's predictions, with lower values signifying higher confidence and better performance.\n","\n","### Evaluating Models with Perplexity\n","\n","In practice, perplexity provides a quantitative measure to compare the performance of different models or the same model at different points in time. For instance, when tuning hyperparameters or making architectural changes, a decrease in perplexity on a validation set would suggest improvements in the model's predictive capabilities.\n","\n","However, it is essential to complement perplexity with other metrics, especially for tasks such as machine translation, summarization, or text generation, where coherence, fluency, and alignment with human judgment are critical. While perplexity can reflect the model's grasp of the language at a word-by-word level, it may not capture the overall quality of text produced in such generative tasks."],"metadata":{"id":"Gb8ZYwJQypbS"}},{"cell_type":"markdown","source":["## Perplexity using evaluate"],"metadata":{"id":"s_pXCpcEDdN9"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Load the perplexity metric\n","perplexity = load(\"perplexity\", module_type=\"metric\")\n","\n","# Define the text samples\n","input_texts = [\"The quick brown fox jumps over the lazy dog.\"]\n","\n","# Calculate perplexity using the pre-trained model 'gpt2'\n","results = perplexity.compute(model_id='gpt2',\n","                             add_start_token=False,\n","                             predictions=input_texts)\n","\n","results\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["22e81d3062dc4b1e87a5f4fdd97d29ca","7e4d222bdf5244f7b0008e1c1832a396","bba6f794b504407fb5af4ce6cf34f0f6","29496fc9d48b45138139427952daec73","059bdf95783e490d87c67357a326755a","acef09cc8cea4e13af11f06ee13d6cc8","8c79b86861d84642b255e0fc8c5f2c62","8a35d590b3254dff87f83d4d46132b97","1c81e15950e74eeca767ea56f577bc55","d36e8096ef174b68a072df925e034d45","e6ed941bc2104fbcb507003d9de1148c"]},"id":"J_p41ASQBREd","executionInfo":{"status":"ok","timestamp":1699734299387,"user_tz":360,"elapsed":9907,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"ba5c0ed0-3ebe-4929-f19d-e06de7b05cb8"},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e81d3062dc4b1e87a5f4fdd97d29ca"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'perplexities': [162.45657348632812], 'mean_perplexity': 162.45657348632812}"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## Calculate Perplexity Manually"],"metadata":{"id":"X8ZE9OapDkfE"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","\n","inputs = tokenizer(\"The quick brown fox jumps over the lazy dog.\",\n","                   return_tensors=\"pt\")\n","\n","outputs = model(input_ids=inputs[\"input_ids\"],\n","             labels=inputs[\"input_ids\"])\n","\n","loss = outputs.loss\n","ppl = torch.exp(loss)\n","\n","print(f\"Perplexity: {ppl.item():.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLqb5E6DCtzL","executionInfo":{"status":"ok","timestamp":1699734423145,"user_tz":360,"elapsed":4883,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"49914163-3f2d-4d9d-9b6f-dac4ac4789cd"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: 162.47\n"]}]},{"cell_type":"code","source":["bperplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n","input_texts = datasets.load_dataset(\"wikitext\",\n","                                    \"wikitext-2-raw-v1\",\n","                                    split=\"test\")[\"text\"][:50]\n","input_texts = [s for s in input_texts if s!='']\n","results = perplexity.compute(model_id='gpt2',\n","                             predictions=input_texts)\n","print(list(results.keys()))\n","print(round(results[\"mean_perplexity\"], 2))\n","print(round(results[\"perplexities\"][0], 2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328,"referenced_widgets":["f4db4f26f7664659be10c43fca080164","05eddccd9d9746e39af0f1ede8040c77","20841b9427754cc0b2562991bfd1d7ad","55c232172f494d3ba38955769a679d7a","04f7492ccb4f40d78485a630c037f3d0","e786fdcb140f4522b980cdcfc0b5567d","cd88f2e83ad749b78b343a18fae82a6c","9a0cb7f9dc824b5e8772ce0d6e4a253b","9186a8b51f9f400f831637a585e01c65","0c4a5749ab7e4f36b9bedfced225c632","52f1ea36421545eb9608f408a03ec0f0","351ad543fbee4718badb0aa419250dca","3fc071b1c6c14513a6872f9d44af66f4","126dabed02264b99804902ef7d51a2a7","6b3edb9720814349a4aeeb6f4fc319e8","030bd33d22f24e53af6d2667404a7b1c","83bf48251f50409ea9aa3475505a878d","2d580f2a8282489d90a9e62687775e34","fd873d052e894d599d572cddf1d04e34","9d1935ae98b34d5ba17afb9c3af4f951","2b7c5495edc94cf0b00f3cfc9fcc594a","97aa09df123b4a9abc8d84927fc4263f","9385cd78af714e3d9e1b5604b6f5ef04","63317b0c034f43baaaf25edfec61225f","d2c1d925238c45658e50d85be392873d","81cd9f58f44e44349836f51822df85dd","879d2838cb9b4faf99d5e3ca26859dfa","aa03aaebd14644fbb2602f73c9edd484","4d37cf63b16e46ee9e6648934380539e","c18adbb0eae54da78b95095a0c171ea7","6f25690b2d58410fb60db83f7af9f45a","33acd12206844a469d238b0ed0052c31","c950b1c8a5064d5d963234cfe127b0ed","1885d2c60c9a4860b4eb2f179a24aa09","d217925b90e842f4af8ed8704b612e96","807b11bcbb47423c86d1404a97430655","0410a32212254556b9b16c2dbacad666","8a107d4fa373487eb00666dd06a6c053","f00b8c9345ce494f922e34acd4ac9ae7","cbd03fed38f5457aa480eb9aac2ce422","fe22ead29b97470d9c682ca0c9212b4b","6d75b59a0afc46bdbfd99e3080e2f526","4034da463e7c4dbbbe4d2a13a5a1a146","97669be6ca834b01a1e69729bc6ec38e","a3329d8747f6474aba7064471f1d556a","c7f834e86d9341a0b3d2c8291f721de2","da26483f73ed407b903dcbb808a7bb24","b54f1f04dae346d49d85e5659a8baeca","f0d8716202e64251a3102e8e89b1bcce","9e4b5c7b6ce6426faac5398ae0f2160b","76bb00d9c9464600a34ad648d7b14670","04a70ba933da40d5967441e4a1037960","1c5acef06b694e77b40d60726626d3c7","345ec05edc4249c7bcac0467500714f8","96bf466910744b0c8461b5093deb490f","9e574456505d45b78ebea14240a1d272","79dc3993a33b44d68ef4943e0ab0edb9","53cfc9b2b1fb405eb9ae7f9f882dd783","bde5f9cff59745d48ff211aba47b6dbe","0811071e1e1b41269199607ce1c3ac98","8f49a1e3c9e2402bb1fc80c99f88bda0","82df8c51139240f5b87913474c95031d","c891db6499b844ff9970b3a62d4abfb6","26951e0317bc46ff91a163ee8f851376","02b249748bfb4683be13f4be52cac85c","b036bd20a2a5445ba0ef3ce38ee5fc53","aa9325bde205464090d16637fa69e50a","936bcdc27c524916852b9ee32e4b33c5","665cee95e627490880976914414e2cee","232416148fa34dc19287d4bb7b416abe","1b19f62ced5e470d8da9024cc6b31b62","771e0c7839134bc5a23bcbad7347416a","a5976adf8cdb47afb27a1455d7478615","c40a59893f654e70b841a9691dd3d51e","505e0156c9b345d38a32783f2d550c01","5b8feb84ea8646aca42ac97a63951630","8beb5b0ee7e44174ac382f09a253661d","2f6051419035491890be90f653f3c1ae","e72a7154fd4c42e0a8845571c672f14b","7d2c0b91f2e04b6381f323637f7d80af","dd7918f6992c4d41a61e3fb52a372199","0903881cc50440b7a27d19b7a5717da6","739cea9d481d4b619da3e3738efd75c6","4b023179ce274a93848e25753b40f1d3","5ef0c880b1c24115a684889b575011e6","6993a1abd6db4a309cd2b88ebf8b30ba","0ee5095ab8194b99b111befff7e4cb39","b02c32be97a846e5be41264bf025a613"]},"id":"2Xy-zyZPC1db","executionInfo":{"status":"ok","timestamp":1699734600415,"user_tz":360,"elapsed":63591,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"8e030197-9a37-41b0-b956-8103be0300d0"},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/8.48k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4db4f26f7664659be10c43fca080164"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351ad543fbee4718badb0aa419250dca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/9.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9385cd78af714e3d9e1b5604b6f5ef04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/4.72M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1885d2c60c9a4860b4eb2f179a24aa09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3329d8747f6474aba7064471f1d556a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e574456505d45b78ebea14240a1d272"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa9325bde205464090d16637fa69e50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f6051419035491890be90f653f3c1ae"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['perplexities', 'mean_perplexity']\n","320.84\n","567.9\n"]}]},{"cell_type":"markdown","source":["# METEOR: Metric for Evaluation of Translation with Explicit Ordering\n","\n","### Overview\n","\n","METEOR is a metric designed for the evaluation of machine translation output, focusing on the harmonic mean of unigram precision and recall, and placing greater emphasis on recall. It aims to align with human judgment at the sentence level, improving upon corpus-level correlation metrics like BLEU.\n","\n","### Algorithm and Matching Techniques\n","\n","METEOR aligns words between candidate and reference sentences using three types of matches:\n","\n","1. **Exact Match**: The algorithm starts by aligning words that are exactly the same in both the hypothesis and reference.\n","2. **Stem Match**:  If an exact match is not found, the algorithm looks for a stem match, where words are aligned if their root forms (stems) match after removing any affixes.\n","3. **Synonym Match**:  Finally, if neither an exact nor a stem match is found, the algorithm checks for synonyms using resources like WordNet.\n","\n","These matches are incorporated into the calculation of precision and recall:\n","\n","$$ P = \\frac{\\text{Number of mapped unigrams in candidate}}{\\text{Total unigrams in candidate}} $$\n","$$ R = \\frac{\\text{Number of mapped unigrams in candidate}}{\\text{Total unigrams in reference}} $$\n","\n","**These are combined using a weighted harmonic mean, with recall being weighted nine times more than precision**\n","\n","$$ F_{\\text{mean}} = \\frac{10 \\cdot P \\cdot R}{R + 9 \\cdot P} $$\n","\n","### Penalty for Fragmentation\n","\n","METEOR applies a penalty for poor ordering of matched words. The penalty is based on the number of chunks of contiguous words in the machine translation that can be mapped to the reference. More and smaller chunks lead to a higher penalty, reflecting the intuition that well-ordered translations should have larger chunks of correctly ordered words.\n","\n","To address alignment of larger segments, METEOR calculates a fragmentation penalty. Unigrams are grouped into chunks of adjacent mappings, with fewer chunks indicating better word order:\n","\n","$$ p = 0.5 \\left( \\frac{c}{u_m} \\right)^3 $$\n","\n","where $ c$ is the number of chunks and $ u_m $ is the number of mapped unigrams. The final score is adjusted based on this penalty, which can reduce it by up to 50% for lack of longer n-gram matches.\n","\n","### Correlation with Human Judgment\n","\n","METEOR correlates strongly with human judgment, showing higher correlation coefficients than BLEU, both at the corpus level (up to 0.964) and at the sentence level (0.403).\n","\n","### Advantages of METEOR\n","\n","- **Alignment with Human Judgment**: It correlates better with human judgment on translation quality compared to BLEU, particularly at the sentence or segment level.\n","- **Recall-Oriented**: By emphasizing recall, METEOR acknowledges the importance of capturing all the content of the reference translation.\n","- **Flexible Matching**: The use of stemming and synonyms allows for a more flexible match between translations and references.\n","\n","### Limitations of METEOR\n","\n","- **Complexity**: METEOR is more computationally intensive than BLEU due to its multi-stage matching process and use of external linguistic resources for stemming and synonyms.\n","- **Language Dependency**: While METEOR is designed to be language-independent, its effectiveness can vary depending on the availability and quality of linguistic resources for the target language.\n","\n","### Conclusion\n","\n","METEOR's multi-faceted approach, which includes exact, stem, and synonym matching, along with a penalty for fragmentation, offers a nuanced assessment of translation quality. Despite its computational intensity, its strong correlation with human judgment makes it a valuable metric for sentence-level evaluation in machine translation.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"xtogu_BJJNIr"}},{"cell_type":"markdown","source":["### **Exact Match**"],"metadata":{"id":"Q_aGsMJKJeys"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Load the METEOR metric\n","meteor = load('meteor')\n","\n","# Example prediction and reference with an exact match\n","predictions = [\"The quick brown fox jumps over the lazy dog\"]\n","reference = [\"The quick brown fox jumps over the lazy dog\"]\n","\n","# Compute METEOR score\n","results = meteor.compute(predictions=predictions, references=reference)\n","\n","# Print the rounded METEOR score\n","print(round(results['meteor'], 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["9ca0a7e587f344d5aaaccadbd24a7e76","da559214910c4b35bef5afd28fd58710","f9a29477cd4b4c59bc092fd4389cb344","f8c42586dc584a41bfd539c82cec795e","e469737193f843488fa234a0de767572","d69d641bd3cb4c2aa46e7f50996a047e","cc100927a28f45acbc1ac0709f1fe2a7","3fefaacd786640dc9885813795aab48f","06d46686d7a64c06b81fca275a836aba","22516092ef9e417dbea6f8647898ab49","fe87ddb560d4444eb26a161363ec600f"]},"id":"Qocsz2GcQH-w","executionInfo":{"status":"ok","timestamp":1699737572842,"user_tz":360,"elapsed":5431,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"0f3ebf22-7624-43be-e475-8a7af0bfa397"},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ca0a7e587f344d5aaaccadbd24a7e76"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]}]},{"cell_type":"markdown","source":["*Explanation:* In this case, the prediction and reference are identical, so the METEOR score should be 1.0, indicating a perfect match.\n"],"metadata":{"id":"MZIQ0ybtQPN7"}},{"cell_type":"markdown","source":["### **Synonym Match**"],"metadata":{"id":"w3SLgOl8QXiL"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Load the METEOR metric\n","meteor = load('meteor')\n","bleu = load('bleu')\n","\n","# Example prediction and multiple references with some synonym matches\n","predictions = [\"The quick brown fox jumps over the lazy dog\"]\n","references = ['The swift brown fox leaps over the lethargic dog']\n","\n","# Compute METEOR score\n","results_meteor = meteor.compute(predictions=predictions, references=references)\n","results_bleu = bleu.compute(predictions=predictions, references=references)\n","\n","# Print the rounded METEOR score\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPC3zaDXQbuD","executionInfo":{"status":"ok","timestamp":1699745047495,"user_tz":360,"elapsed":5557,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"411c12a2-08e6-4699-f801-1f4a7d06269f"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","source":["results_meteor, results_bleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D218WYCRRM1G","executionInfo":{"status":"ok","timestamp":1699745050763,"user_tz":360,"elapsed":263,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"1a0c19c4-b786-474d-d9c6-ddcbb399399b"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'meteor': 0.7471655328798186},\n"," {'bleu': 0.0,\n","  'precisions': [0.6666666666666666, 0.25, 0.0, 0.0],\n","  'brevity_penalty': 1.0,\n","  'length_ratio': 1.0,\n","  'translation_length': 9,\n","  'reference_length': 9})"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["*Explanation:* Even though there's no exact match, METEOR considers synonyms and similar phrases. The score reflects how well the prediction aligns with the references in terms of meaning.\n"],"metadata":{"id":"tQS23xPVQjC-"}},{"cell_type":"markdown","source":["## **Multiple References Per Prediction (Partial Match):**"],"metadata":{"id":"phABJdYoRdZR"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Load the METEOR metric\n","meteor = load('meteor')\n","\n","# Example prediction and multiple references with partial matches\n","predictions = [\"The quick brown fox jumps over the lazy dog\"]\n","references = [['A fast fox leaps over a dog',\n","               'An agile fox hurdles a sleeping dog',\n","               'A rapid fox skips over a dog resting']]\n","\n","# Compute METEOR score\n","results = meteor.compute(predictions=predictions, references=references)\n","\n","# Print the rounded METEOR score\n","print(round(results['meteor'], 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-rlAoXPRs5Z","executionInfo":{"status":"ok","timestamp":1699737971396,"user_tz":360,"elapsed":2600,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"3e3fbd10-7a98-4ac1-c271-c72e9816ec28"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["0.62\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["*Explanation:* Here, the prediction and references share some common words and meanings, but the alignment is not as strong as in the exact or synonym match scenarios. The METEOR score will be lower than 1.0 but should still capture the partial match.\n","\n","In each case, the `evaluate` library computes the METEOR score based on the best alignment between the prediction and the references, considering exact matches, stem matches, and synonymy. The score provides insight into the translation quality from a semantic perspective."],"metadata":{"id":"Wly9WgN4Rxfl"}},{"cell_type":"markdown","source":["# BERTScore\n","### Overview\n","BERTScore is an advanced metric for evaluating the quality of text generation tasks, such as summarization and translation. It leverages the power of pre-trained language models beyond BERT, like RoBERTa, XLNet, and XLM, to capture the contextual relationships between words in a given text.\n","\n","### Embeddings\n","BERTScore uses the contextual embeddings from these models, which reflect the surrounding context of each token in the text, providing a rich semantic representation.\n","\n","### Recall\n","Recall in BERTScore is measured by taking each token in the reference text and finding its most similar counterpart in the candidate text using cosine similarity of their embeddings.\n","\n","$$ R_{BERT} = \\frac{1}{|X|} \\sum_{x_i \\in X} \\max_{y_j \\in Y} \\cos(x_i, y_j) $$\n","\n","### Precision\n","Precision is calculated similarly but inverts the relationship; each token in the candidate text is compared to the reference text.\n","\n","$$ P_{BERT} = \\frac{1}{|Y|} \\sum_{y_i \\in Y} \\max_{x_j \\in X} \\cos(y_i, x_j) $$\n","\n","### F1 Score\n","The F1 score is the harmonic mean of precision and recall, providing a single score that balances both aspects.\n","\n","$$ F_{BERT} = \\frac{2 \\cdot P_{BERT} \\cdot R_{BERT}}{P_{BERT} + R_{BERT}} $$\n","\n","### Weighting\n","Optionally, an importance weighting based on Inverse Document Frequency (IDF) can be applied to each token, emphasizing the significance of rarer words.\n","\n","### Rescaling\n","To enhance interpretability, BERTScore values are linearly rescaled based on baselines derived from a monolingual dataset, ensuring the scores fall within an intuitive range.\n","\n","The rescaling equation for BERTScore is:\n","\n","$$ \\hat{R}_{BERT} = \\frac{R_{BERT} - b}{1 - b} $$\n","\n","Here's the revised Rescaling section with an explanation:\n","\n","The baseline $ b $ in the BERTScore rescaling equation is a precomputed constant number, specific to the language model and the dataset it was derived from. It is calculated in advance using a representative set of reference-candidate pairs from a relevant monolingual dataset. This baseline $ b $ does not change with each new input; it is used consistently to rescale BERTScore values across different inputs to maintain comparability and interpretability.\n","\n","### Advantages\n","BERTScore's emphasis on semantic content makes it robust to paraphrasing and offers a more meaningful assessment than overlap-based metrics.\n","\n","### Disadvantages\n","However, its computational intensity and dependency on the quality of pre-trained embeddings can be limiting factors.\n","\n","### Conclusion\n","BERTScore stands out for its semantic evaluation capabilities, offering significant benefits for many NLP tasks. Its potential for broader language coverage and adaptation to various text types makes it a promising tool for future advancements in language processing."],"metadata":{"id":"rqvsmdVUpZqk"}},{"cell_type":"markdown","source":["### **Exact Match**"],"metadata":{"id":"8A6VOVnstbDv"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Load the METEOR metric\n","meteor = load('bertscore')\n","\n","# Example prediction and reference with an exact match\n","predictions = [\"The quick brown fox jumps over the lazy dog\"]\n","reference = [\"The quick brown fox jumps over the lazy dog\"]\n","\n","# Compute METEOR score\n","results = meteor.compute(predictions=predictions, references=reference, model_type=\"distilbert-base-uncased\")\n","\n","# Print the rounded METEOR score\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WgKPUwMpejv","executionInfo":{"status":"ok","timestamp":1699744989294,"user_tz":360,"elapsed":5632,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"691a4934-0462-4002-a597-8e1ad24f0650"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'precision': [1.0000001192092896],\n"," 'recall': [1.0000001192092896],\n"," 'f1': [1.0000001192092896],\n"," 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.35.0)'}"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["### **Synonym Match**"],"metadata":{"id":"eCuGRksCtg2N"}},{"cell_type":"code","source":["from evaluate import load\n","\n","# Load the METEOR metric\n","meteor = load('meteor')\n","bleu = load('bleu')\n","bert = load('bertscore')\n","\n","# Example prediction and multiple references with some synonym matches\n","predictions = [\"The quick brown fox jumps over the lazy dog\"]\n","references = ['The swift brown fox leaps over the lethargic dog']\n","\n","# Compute METEOR score\n","results_meteor = meteor.compute(predictions=predictions, references=references)\n","results_bleu = bleu.compute(predictions=predictions, references=references)\n","results_bert = bert.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knrrMtD6silU","executionInfo":{"status":"ok","timestamp":1699745127796,"user_tz":360,"elapsed":9390,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"cb86a390-c1bc-485e-d063-db99bd875a1a"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","source":["results_meteor, results_bleu, results_bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rs9BF5zetDeH","executionInfo":{"status":"ok","timestamp":1699745145185,"user_tz":360,"elapsed":256,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"}},"outputId":"c0151b77-4e29-4cfa-c876-38d481d98170"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'meteor': 0.7471655328798186},\n"," {'bleu': 0.0,\n","  'precisions': [0.6666666666666666, 0.25, 0.0, 0.0],\n","  'brevity_penalty': 1.0,\n","  'length_ratio': 1.0,\n","  'translation_length': 9,\n","  'reference_length': 9},\n"," {'precision': [0.9558224678039551],\n","  'recall': [0.9063857793807983],\n","  'f1': [0.9304479360580444],\n","  'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.35.0)'})"]},"metadata":{},"execution_count":74}]}]}
